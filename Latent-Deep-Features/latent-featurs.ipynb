{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéâ Out-of-Distribution (OOD) with PCA using Deep Features from the Latent Space\n",
    "\n",
    "The goal of this notebook is to understand the depths of using Principal Component Analysis in order to perform OOD tasks using deep features from the latent space\n",
    "\n",
    "## üìù Plan of action\n",
    "\n",
    "### ‚ôªÔ∏è Preprocessing phase\n",
    "\n",
    "In order to achieve our goal, we need to understand how the dataset is structured.\n",
    "\n",
    "For this notebook, we are going to use the CBIR 15 dataset, that contains images of different places, such as an office, a bedroom, a mountain, etc. Note that there are some places that are similar one to another, i.e. a bedroom and a living room.\n",
    "\n",
    "Thus, in order to extract the features of the images we have to preprocess those images:\n",
    "\n",
    "- Get the images that are located in data/CBIR_15-scene and fit them to a dataframe using Pandas\n",
    "  - Locate the \"Labels.txt\" file: it shows where the indexes of the images from each category starts\n",
    "- Create the dataset with this information with two columns: the path to the image and its category\n",
    "- Transform all of the images in the same size (in this case, we are going with 256x256)\n",
    "  \n",
    "Now, in order to extract the features, it's necessary to divide the reshaped images into patches of 32x32 pixels. This is good to perform processing tasks to avoid waiting long periods of time.\n",
    "\n",
    "After all the preprocess, we should separate the images into two different foldes: one contains the patches of the training images that is going to give us their principal components and dimensions, and the other is the patches of the test images, that is going to be tested to fit into those dimensions and we'll get an OOD score afterwards.\n",
    "\n",
    "### üèãüèΩ‚Äç‚ôÇÔ∏è Training phase\n",
    "\n",
    "With the images that are stored inside the \"patches_train\" folder, the first thing we are going to do is _normalize_ all of the images to find the correct maximum covariance and transforming all the variables into the same scale.\n",
    "\n",
    "Next, we should then apply the PCA with all the components. As we have patches of 32x32, we'll be having 1024 features, hence components. Then we plot a graph to see how many components truly contributes for the most variance of the data - and give us more information about it. We're going to take the threshold of 95% of variance in this notebook.\n",
    "\n",
    "After getting the PCA with components that describe 95% of the variance, it's time to test our images and see how far of the residual space their data can be found.\n",
    "\n",
    "### ‚öóÔ∏è Test phase and results\n",
    "\n",
    "In this phase, we take the test images and normalize then with the same scale of each PCA. This is important to maintain consistency throughout the final results and measure the norms in the new dimension properly.\n",
    "\n",
    "After that, we calculate the norm of the projection of the given data into the orthogonal space of the principal component and divide it by the norm of the data in relation to the origin. This is the OOD score.\n",
    "\n",
    "We calculate the mean of the score for each category and get the minimal one. The current environment is the smallest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "First of all, we need to understand which libraries we are going to use:\n",
    "\n",
    "- os: Deals with the operation system interface such as finding the relative and absolute path of files inside a project and reading/writing files for example.\n",
    "- sys: This module provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter.\n",
    "- numpy: NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\n",
    "- pandas: Pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "- matplotlib: Deals with plotting graphs to visualize data in a graphical way.\n",
    "- sklearn: Scikit-learn provides dozens of built-in machine learning algorithms and models, called estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd suggest to use a conda virtual environment in order to avoid messing up your base kernel environment and causing dependency errors in the future.\n",
    "\n",
    "After you successfully installed all the modules, it's time to import our custom modules that are going to deal with:\n",
    "\n",
    "- Creation of our dataframe using pandas\n",
    "- Separation of our dataset into patches of 32x32 in folders of training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from dataframe_generator import *\n",
    "from images_standardizing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "def extract_tgz(tgz_path, extract_to):\n",
    "    if not os.path.exists(extract_to):\n",
    "        os.makedirs(extract_to)\n",
    "    \n",
    "    with tarfile.open(tgz_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=extract_to)\n",
    "        print(f\"Arquivos extra√≠dos para {extract_to}\")\n",
    "\n",
    "tgz_path = '../CBIR_15-Scene.tgz'\n",
    "extract_to = '../data/'\n",
    "\n",
    "extract_tgz(tgz_path, extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataframe()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òùÔ∏è Part I: Comparing two different environments\n",
    "\n",
    "### ‚ôªÔ∏è Preprocessing phase\n",
    "\n",
    "Now we start our experiments to understand if our idea work, however this time we are going to understand what happens with our approach using two different environments.\n",
    "\n",
    "In our case, I'm going to take the **Coast** and **Office** environments arbitrarily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categories = ['Coast', 'Office']\n",
    "\n",
    "df_different = df[df['category'].isin(train_categories)]\n",
    "df_different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to separate our dataset into train and test. We should use the built-in function of sklearn to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_different['image_path'].tolist()\n",
    "y = df_different['category'].tolist()\n",
    "unique_categories = list(df_different['category'].unique())\n",
    "print(f\"Unique categories: {unique_categories}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "standard_size = (256, 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure that everything went well, we plot the grid of all the patches from the first image of our training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is exactly what the module that's inside our \"image_patching.py\" do. So we now, need to save everything into the subfolders by calling that function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_images_set(X_train, X_test, y_train, y_test, output_dir_train='images_train', output_dir_test='images_test', standard_size=standard_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should load our patches for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images_by_category = load_images_by_category('images_train', unique_categories, image_size=(256, 256))\n",
    "print(training_images_by_category['Coast'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Centering images\n",
    "\n",
    "Now, we need to center the images to make the neural network more efficient. We are not normalizing it to avoid information loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_images(images):\n",
    "    num_images, height, width = images.shape\n",
    "    flattened_images = images.reshape((num_images, -1))\n",
    "    \n",
    "    mean = np.mean(flattened_images, axis=0)\n",
    "    \n",
    "    centered_flattened_images = flattened_images - mean\n",
    "    \n",
    "    centered_images = centered_flattened_images.reshape((num_images, height, width))\n",
    "    return centered_images\n",
    "\n",
    "\n",
    "centralized_images_by_category = {}\n",
    "scalers_by_category = {}\n",
    "for category, images in training_images_by_category.items():\n",
    "    print(images.shape)\n",
    "    centralized_images = center_images(images)\n",
    "    centralized_images_by_category[category] = centralized_images\n",
    "    print(f\"Category {category}, images shape: {centralized_images.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_centralization(images):\n",
    "    mean = np.mean(images, axis=(0, 1, 2))\n",
    "    return mean\n",
    "\n",
    "for category, images in centralized_images_by_category.items():\n",
    "    mean = check_centralization(images)\n",
    "    print(f\"Mean pixel values after centralization for category {category}: {mean}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the values close to zero, it means that the pixels for each color channel are correctly centralized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üèãüèΩ‚Äç‚ôÇÔ∏è Training phase\n",
    "\n",
    "With everything preprocessed, we now need to train our neural network. In this notebook, I chose the VGG16 because it's a well-known neural network that is often used por computer vision applications.\n",
    "\n",
    "I'm using no weights, because the underlining goal of this research is to use the results from this work in a unsupervised environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Verifica o dispositivo dispon√≠vel (GPU ou CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Define o modelo UNet para codificar e decodificar\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder1 = self.contracting_block(in_channels, 64)\n",
    "        self.encoder2 = self.contracting_block(64, 128)\n",
    "        self.encoder3 = self.contracting_block(128, 256)\n",
    "        self.encoder4 = self.contracting_block(256, 512)\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder4 = self.expansive_block(512, 256)\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder3 = self.expansive_block(256, 128)\n",
    "        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder2 = self.expansive_block(128, 64)\n",
    "        self.decoder1 = self.final_block(64, out_channels)\n",
    "\n",
    "    def contracting_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=3, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def expansive_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=3, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def final_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=3, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=1, in_channels=out_channels, out_channels=out_channels),\n",
    "            nn.Sigmoid()  # Adiciona ativa√ß√£o sigmoid para garantir que a sa√≠da fique entre [0, 1]\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def crop_and_concat(self, upsampled, bypass):\n",
    "        _, _, H, W = upsampled.size()\n",
    "        _, _, H_b, W_b = bypass.size()\n",
    "        if H_b != H or W_b != W:\n",
    "            bypass = nn.functional.interpolate(bypass, size=(H, W), mode='bilinear', align_corners=True)\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(nn.functional.max_pool2d(enc1, kernel_size=2, stride=2))\n",
    "        enc3 = self.encoder3(nn.functional.max_pool2d(enc2, kernel_size=2, stride=2))\n",
    "        enc4 = self.encoder4(nn.functional.max_pool2d(enc3, kernel_size=2, stride=2))\n",
    "\n",
    "        # Decoder path\n",
    "        dec4 = self.crop_and_concat(self.upconv4(enc4), enc3)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.crop_and_concat(self.upconv3(dec4), enc2)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.crop_and_concat(self.upconv2(dec3), enc1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.decoder1(dec2)\n",
    "\n",
    "        return dec1, enc1, enc2, enc3, enc4  # Retorna tanto a imagem reconstru√≠da quanto as features do encoder\n",
    "\n",
    "def apply_pca_and_reconstruct(features, pca):\n",
    "    # Flatten the features while keeping track of the original shape\n",
    "    batch_size, channels, height, width = features.size()\n",
    "    flattened_features = features.view(batch_size, -1).cpu().numpy()\n",
    "\n",
    "    # Verifica as dimens√µes originais das features\n",
    "    original_num_features = flattened_features.shape[1]\n",
    "    print(f\"Original number of features before PCA: {original_num_features}\")\n",
    "\n",
    "    # Apply PCA projection and reconstruction\n",
    "    projected_features = pca.transform(flattened_features)\n",
    "    num_pca_components = projected_features.shape[1]\n",
    "    print(f\"Number of components after PCA: {num_pca_components}\")\n",
    "\n",
    "    reconstructed_features = pca.inverse_transform(projected_features)\n",
    "    #print(f\"Reconstructed feature dimensions (after inverse PCA): {reconstructed_features.shape}\")\n",
    "\n",
    "    # Convert back to tensor and reshape to the original feature shape\n",
    "    reconstructed_features = torch.tensor(reconstructed_features, dtype=torch.float32).view(batch_size, channels, height, width).to(device)\n",
    "\n",
    "    return reconstructed_features\n",
    "\n",
    "# Fun√ß√£o para treinar e aplicar PCA nas features extra√≠das da U-Net com verifica√ß√£o de vari√¢ncia explicada\n",
    "def train_unet_and_apply_pca(unet, data_loader, num_epochs=5):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(unet.parameters(), lr=0.0001)\n",
    "\n",
    "    global pca_train_features\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        unet.train()\n",
    "        epoch_loss = 0\n",
    "        for images, in data_loader:\n",
    "            images = images.to(device).float()\n",
    "            images /= 255.0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through U-Net to get features\n",
    "            reconstructed_images, _, _, _, unet_features = unet(images)\n",
    "\n",
    "            # Flatten and collect features for PCA training (in the first epoch)\n",
    "            if epoch == 0:\n",
    "                flattened_features = unet_features.view(images.shape[0], -1).detach().cpu().numpy()\n",
    "                if 'pca_train_features' not in globals():\n",
    "                    pca_train_features = flattened_features\n",
    "                else:\n",
    "                    pca_train_features = np.vstack((pca_train_features, flattened_features))\n",
    "\n",
    "            loss = criterion(reconstructed_images, images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(data_loader):.4f}')\n",
    "\n",
    "    # Calcula e exibe o n√∫mero de features antes do PCA\n",
    "    original_feature_count = pca_train_features.shape[1]\n",
    "    print(f\"Original number of features before PCA: {original_feature_count}\")\n",
    "\n",
    "    # Aplicando o PCA e mostrando a vari√¢ncia explicada\n",
    "    pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "    pca.fit(pca_train_features)\n",
    "    print(f\"Explained variance by PCA components: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Number of components chosen by PCA: {pca.n_components_}\")\n",
    "\n",
    "    return pca\n",
    "\n",
    "# Inicializa√ß√£o do modelo UNet\n",
    "unet = UNet().to(device)\n",
    "\n",
    "# Dicion√°rio para armazenar o PCA de cada categoria\n",
    "pca_dict = {}\n",
    "\n",
    "# Defina o DataLoader aqui\n",
    "categories = centralized_images_by_category.keys()\n",
    "\n",
    "for category in categories:\n",
    "    images = centralized_images_by_category[category]\n",
    "\n",
    "    # Adiciona a dimens√£o do canal e cria o DataLoader\n",
    "    images = np.expand_dims(images, axis=1)  # Adiciona dimens√£o do canal\n",
    "    dataset = TensorDataset(torch.tensor(images, dtype=torch.float32))\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # Treina o modelo U-Net e coleta features para o PCA\n",
    "    pca = train_unet_and_apply_pca(unet, loader, num_epochs=5)\n",
    "\n",
    "    # Armazena o PCA no dicion√°rio para a categoria atual\n",
    "    pca_dict[category] = pca\n",
    "\n",
    "    # Avalia e visualiza algumas imagens reconstru√≠das com PCA aplicado nas features\n",
    "    unet.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(3):  # Exibe 3 imagens de cada categoria\n",
    "            image = centralized_images_by_category[category][i]\n",
    "            image_tensor = torch.tensor(image / 255.0).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "            # Processa com UNet e extrai features\n",
    "            reconstructed_image, enc1, enc2, enc3, unet_features = unet(image_tensor)\n",
    "\n",
    "            # Aplica PCA nas features e reconstr√≥i as features\n",
    "            reconstructed_features = apply_pca_and_reconstruct(unet_features, pca)\n",
    "\n",
    "            # Passa as features reconstru√≠das pelo caminho de decodifica√ß√£o da U-Net\n",
    "            dec4 = unet.crop_and_concat(unet.upconv4(reconstructed_features), enc3)\n",
    "            dec4 = unet.decoder4(dec4)\n",
    "            dec3 = unet.crop_and_concat(unet.upconv3(dec4), enc2)\n",
    "            dec3 = unet.decoder3(dec3)\n",
    "            dec2 = unet.crop_and_concat(unet.upconv2(dec3), enc1)\n",
    "            dec2 = unet.decoder2(dec2)\n",
    "\n",
    "            # Corrige o n√∫mero de canais esperados pela √∫ltima camada de convolu√ß√£o\n",
    "            final_reconstructed_image = unet.decoder1(dec2)\n",
    "\n",
    "            # Converte o tensor para numpy para visualiza√ß√£o\n",
    "            final_reconstructed_image_np = final_reconstructed_image.squeeze().cpu().numpy()\n",
    "\n",
    "            # Visualiza as imagens\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.title(f'Original {category} Image {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(final_reconstructed_image_np, cmap='gray')\n",
    "            plt.title(f'Reconstructed {category} Image {i+1} with PCA')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "# Salva o dicion√°rio de PCA para uso posterior\n",
    "print(\"PCA models saved for each category.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we get the before last layer's output to extract our latent features from the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result means that we extracted 348 images with 4096 features each of the Coast category and 209 images with 4096 features each of the Office category.\n",
    "\n",
    "Now we have to reduce the dimensonality. In order to do that, we should use PCA techniques. But before that, we should centralize the features now."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components_ matrix has the shape (n_components, n_features), but when you project the original data into this new principal components space, the data is transformed into a shape matrix (n_samples, n_components)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_test_images(test_dir, categories, image_size, input_size=(224,224)):\n",
    "    test_images_by_category = load_images_by_category(test_dir, categories, image_size)\n",
    "    test_centralized_images_by_category = {}\n",
    "\n",
    "    for category, images in test_images_by_category.items():\n",
    "        test_centralized_images = center_images(images)\n",
    "        test_centralized_images_by_category[category] = test_centralized_images\n",
    "\n",
    "    return test_centralized_images_by_category\n",
    "\n",
    "test_preprocessed_images_by_category = load_and_preprocess_test_images('images_test', y, image_size=(256,256), input_size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, images in test_preprocessed_images_by_category.items():\n",
    "    mean = check_centralization(images)\n",
    "    print(f\"Mean pixel values after centralization for category {category}: {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to apply UNet with different PCA models, compute OOD scores, and visualize the first 3 results\n",
    "def compute_ood_and_visualize(unet, pca_dict, test_images_by_category):\n",
    "    unet.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Dictionary to store OOD scores for each test category and PCA category\n",
    "    ood_scores_by_category = {}\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for test_category, test_images in test_images_by_category.items():\n",
    "            print(f\"Processing test category: {test_category}\")\n",
    "\n",
    "            # Store OOD scores for this test category\n",
    "            ood_scores_by_category[test_category] = {}\n",
    "\n",
    "            # Iterate over PCA models from different categories\n",
    "            for pca_category in pca_dict.keys():\n",
    "                ood_scores_by_category[test_category][pca_category] = []\n",
    "\n",
    "                # Process all test images in this category\n",
    "                for i, image in enumerate(test_images):\n",
    "                    image_tensor = torch.tensor(image / 255.0).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "                    # Forward pass through UNet to get features\n",
    "                    reconstructed_image, enc1, enc2, enc3, unet_features = unet(image_tensor)\n",
    "\n",
    "                    # Apply PCA to the features and reconstruct them\n",
    "                    reconstructed_features = apply_pca_and_reconstruct(unet_features, pca_dict[pca_category])\n",
    "\n",
    "                    # Calculate residuals\n",
    "                    residuals = unet_features - reconstructed_features\n",
    "\n",
    "                    # Calculate norms for OOD score\n",
    "                    norm_residuals = torch.norm(residuals)\n",
    "                    norm_original = torch.norm(unet_features)\n",
    "\n",
    "                    # Compute OOD score\n",
    "                    ood_score = (norm_residuals / norm_original).item()\n",
    "                    ood_scores_by_category[test_category][pca_category].append(ood_score)\n",
    "\n",
    "                    # Only plot the reconstruction for the first 3 images in each category\n",
    "                    if i < 3:\n",
    "                        # Pass the reconstructed features through the decoder of the UNet\n",
    "                        dec4 = unet.crop_and_concat(unet.upconv4(reconstructed_features), enc3)\n",
    "                        dec4 = unet.decoder4(dec4)\n",
    "                        dec3 = unet.crop_and_concat(unet.upconv3(dec4), enc2)\n",
    "                        dec3 = unet.decoder3(dec3)\n",
    "                        dec2 = unet.crop_and_concat(unet.upconv2(dec3), enc1)\n",
    "                        dec2 = unet.decoder2(dec2)\n",
    "                        final_reconstructed_image = unet.decoder1(dec2)\n",
    "\n",
    "                        # Convert the tensor to numpy for visualization\n",
    "                        final_reconstructed_image_np = final_reconstructed_image.squeeze().cpu().numpy()\n",
    "\n",
    "                        # Plot original and reconstructed images\n",
    "                        plt.figure(figsize=(10, 5))\n",
    "                        plt.subplot(1, 2, 1)\n",
    "                        plt.imshow(image, cmap='gray')\n",
    "                        plt.title(f'Original {test_category} Image {i+1}')\n",
    "                        plt.axis('off')\n",
    "\n",
    "                        plt.subplot(1, 2, 2)\n",
    "                        plt.imshow(final_reconstructed_image_np, cmap='gray')\n",
    "                        plt.title(f'Reconstructed {test_category} Image {i+1} with {pca_category} PCA')\n",
    "                        plt.axis('off')\n",
    "\n",
    "                        plt.show()\n",
    "\n",
    "    # Calculate average OOD score for each category with each PCA\n",
    "    avg_ood_scores_by_category = {}\n",
    "\n",
    "    for test_category, pca_ood_scores in ood_scores_by_category.items():\n",
    "        avg_ood_scores_by_category[test_category] = {}\n",
    "        for pca_category, ood_scores in pca_ood_scores.items():\n",
    "            avg_ood_score = np.mean(ood_scores)\n",
    "            avg_ood_scores_by_category[test_category][pca_category] = avg_ood_score\n",
    "            print(f\"Average OOD Score for {test_category} with {pca_category} PCA: {avg_ood_score}\")\n",
    "\n",
    "    return avg_ood_scores_by_category\n",
    "\n",
    "# Assuming you have already trained your U-Net and saved the PCA models for each category:\n",
    "avg_ood_scores_by_category = compute_ood_and_visualize(unet, pca_dict, test_preprocessed_images_by_category)\n",
    "\n",
    "# Print the average OOD scores for all categories\n",
    "for test_category, pca_ood_scores in avg_ood_scores_by_category.items():\n",
    "    print(f\"\\nAverage OOD Scores for test category '{test_category}':\")\n",
    "    for pca_category, avg_ood in pca_ood_scores.items():\n",
    "        print(f\"  PCA from '{pca_category}' => Average OOD Score: {avg_ood}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agnostic Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "# Function to project features onto selected PCA components and transform back\n",
    "def project_and_transform_back(data, pca, specific_indices):\n",
    "    \"\"\"\n",
    "    Project the data onto specific PCA components, reconstruct the data, and calculate residuals and OOD score.\n",
    "    \"\"\"\n",
    "    # Flatten the features for PCA projection\n",
    "    flattened_data = data.view(1, -1).cpu().numpy()\n",
    "    \n",
    "    # Project onto the PCA components\n",
    "    projected = pca.transform(flattened_data)\n",
    "    \n",
    "    # Use only the specific components\n",
    "    projected_specific = projected[:, specific_indices]\n",
    "    \n",
    "    # Reconstruct the data from the selected components\n",
    "    specific_components = pca.components_[specific_indices]\n",
    "    reconstructed_data = np.dot(projected_specific, specific_components)\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals = flattened_data - reconstructed_data\n",
    "    \n",
    "    # Calculate norms for OOD score\n",
    "    norm_residuals = np.linalg.norm(residuals)\n",
    "    norm_original = np.linalg.norm(flattened_data)\n",
    "    \n",
    "    # Calculate OOD score as the ratio of the norms\n",
    "    ood_score = norm_residuals / norm_original\n",
    "    \n",
    "    return reconstructed_data, residuals, ood_score\n",
    "def compute_ood_with_selected_components(unet, pca_dict, test_images_by_category):\n",
    "    unet.eval()  # Set UNet to evaluation mode\n",
    "    \n",
    "    # Dictionary to store OOD scores for each test category and PCA category\n",
    "    ood_scores_by_category = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_category, test_images in test_images_by_category.items():\n",
    "            print(f\"Processing test category: {test_category}\")\n",
    "\n",
    "            ood_scores_by_category[test_category] = {}\n",
    "\n",
    "            # Iterate over PCA models from different categories\n",
    "            for pca_category, pca in pca_dict.items():\n",
    "                print(f\"Processing with PCA from category: {pca_category}\")\n",
    "                ood_scores_by_category[test_category][pca_category] = []\n",
    "\n",
    "                # Retrieve explained variance ratio and components from the PCA object\n",
    "                explained_variance_ratio = pca.explained_variance_ratio_\n",
    "                components = pca.components_\n",
    "\n",
    "                all_selected_indices = []\n",
    "\n",
    "                # Process each image in the test category\n",
    "                for i, image in enumerate(test_images):\n",
    "                    # Prepare image tensor and extract UNet features\n",
    "                    image_tensor = torch.tensor(image / 255.0).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "                    reconstructed_image, enc1, enc2, enc3, unet_features = unet(image_tensor)\n",
    "\n",
    "                    # Flatten UNet features for PCA projection\n",
    "                    flattened_features = unet_features.view(1, -1).cpu().numpy()\n",
    "\n",
    "                    # Project and select PCA components\n",
    "                    norms_category = np.linalg.norm(components, axis=1)\n",
    "                    selected_indices = np.where(np.cumsum(explained_variance_ratio) <= 0.9)[0]\n",
    "                    all_selected_indices.append(selected_indices)\n",
    "\n",
    "                # Aggregate selected components across all images\n",
    "                aggregated_selected_indices = np.unique(np.concatenate(all_selected_indices))\n",
    "\n",
    "                # Skip processing if no valid components are selected\n",
    "                if len(aggregated_selected_indices) == 0:\n",
    "                    print(f\"Warning: No valid components selected for {test_category} with {pca_category} PCA. Skipping this combination.\")\n",
    "                    continue\n",
    "\n",
    "                # Process each image again using selected components for projection, reconstruction, and OOD calculation\n",
    "                for i, image in enumerate(test_images):\n",
    "                    image_tensor = torch.tensor(image / 255.0).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "                    reconstructed_image, enc1, enc2, enc3, unet_features = unet(image_tensor)\n",
    "\n",
    "                    # Project and reconstruct features using only the selected PCA components\n",
    "                    reconstructed_features, residuals, ood_score = project_and_transform_back(unet_features, pca, aggregated_selected_indices)\n",
    "\n",
    "                    # Reshape the residuals to the same shape as `unet_features`\n",
    "                    residuals_reshaped = residuals.reshape(unet_features.shape)  # Reshape to (B, C, H, W)\n",
    "\n",
    "                    # Append the OOD score\n",
    "                    ood_scores_by_category[test_category][pca_category].append(ood_score)\n",
    "\n",
    "                    # Visualize the first 3 images with their reconstructions and residuals\n",
    "                    if i < 3:\n",
    "                        # Pass the reconstructed features through the decoder of the UNet\n",
    "                        dec4 = unet.crop_and_concat(unet.upconv4(torch.tensor(reconstructed_features, dtype=torch.float32).view_as(unet_features).to(device)), enc3)\n",
    "                        dec4 = unet.decoder4(dec4)\n",
    "                        dec3 = unet.crop_and_concat(unet.upconv3(dec4), enc2)\n",
    "                        dec3 = unet.decoder3(dec3)\n",
    "                        dec2 = unet.crop_and_concat(unet.upconv2(dec3), enc1)\n",
    "                        dec2 = unet.decoder2(dec2)\n",
    "                        final_reconstructed_image = unet.decoder1(dec2)\n",
    "\n",
    "                        # Convert to numpy for visualization\n",
    "                        final_reconstructed_image_np = final_reconstructed_image.squeeze().cpu().numpy()\n",
    "\n",
    "                        # Convert residuals to numpy for visualization\n",
    "                        residuals_np = residuals_reshaped.squeeze()  # Residuals are already in NumPy format\n",
    "\n",
    "                        # Plot original, reconstructed, and residual images\n",
    "                        plt.figure(figsize=(15, 5))\n",
    "                        plt.subplot(1, 3, 1)\n",
    "                        plt.imshow(image, cmap='gray')\n",
    "                        plt.title(f'Original {test_category} Image {i+1}')\n",
    "                        plt.axis('off')\n",
    "\n",
    "                        plt.subplot(1, 3, 2)\n",
    "                        plt.imshow(final_reconstructed_image_np, cmap='gray')\n",
    "                        plt.title(f'Reconstructed {test_category} Image {i+1} with {pca_category} PCA')\n",
    "                        plt.axis('off')\n",
    "\n",
    "                        plt.subplot(1, 3, 3)\n",
    "                        plt.imshow(residuals_np[0], cmap='gray')  # Select the first channel for visualization\n",
    "                        plt.title(f'Residuals {test_category} Image {i+1} with {pca_category} PCA')\n",
    "                        plt.axis('off')\n",
    "\n",
    "                        plt.show()\n",
    "\n",
    "    # Calculate average OOD score for each category and PCA\n",
    "    avg_ood_scores_by_category = {}\n",
    "    for test_category, pca_ood_scores in ood_scores_by_category.items():\n",
    "        avg_ood_scores_by_category[test_category] = {}\n",
    "        for pca_category, ood_scores in pca_ood_scores.items():\n",
    "            avg_ood_score = np.mean(ood_scores)\n",
    "            avg_ood_scores_by_category[test_category][pca_category] = avg_ood_score\n",
    "            print(f\"Average OOD Score for {test_category} with {pca_category} PCA: {avg_ood_score}\")\n",
    "\n",
    "    return avg_ood_scores_by_category\n",
    "\n",
    "# Assuming you have already trained your U-Net and saved the PCA models for each category\n",
    "avg_ood_scores_by_category = compute_ood_with_selected_components(unet, pca_dict, test_preprocessed_images_by_category)\n",
    "\n",
    "# Print the average OOD scores for all categories\n",
    "for test_category, pca_ood_scores in avg_ood_scores_by_category.items():\n",
    "    print(f\"\\nAverage OOD Scores for test category '{test_category}':\")\n",
    "    for pca_category, avg_ood in pca_ood_scores.items():\n",
    "        print(f\"  PCA from '{pca_category}' => Average OOD Score: {avg_ood}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úåÔ∏è Part II: Comparing two similar environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categories = ['Bedroom', 'LivingRoom']\n",
    "\n",
    "df_different = df[df['category'].isin(train_categories)]\n",
    "df_different"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_different['image_path']\n",
    "y = df_different['category']\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "image_size = (256, 256)\n",
    "unique_categories = list(df_different['category'].unique())\n",
    "print(f\"Unique categories: {unique_categories}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_images_set(X_train, X_test, y_train, y_test, output_dir_train='images_train', output_dir_test='images_test', standard_size=standard_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images_by_category = load_images_by_category('images_train', unique_categories, image_size=(256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centralized_images_by_category = {}\n",
    "scalers_by_category = {}\n",
    "for category, images in training_images_by_category.items():\n",
    "    centralized_images = center_images(images)\n",
    "    centralized_images_by_category[category] = centralized_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_centralization(images):\n",
    "    mean = np.mean(images, axis=(0, 1, 2))\n",
    "    return mean\n",
    "\n",
    "for category, images in centralized_images_by_category.items():\n",
    "    mean = check_centralization(images)\n",
    "    print(f\"Mean pixel values after centralization for category {category}: {mean}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Verifica o dispositivo dispon√≠vel (GPU ou CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Define o modelo UNet para codificar e decodificar\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder1 = self.contracting_block(in_channels, 64)\n",
    "        self.encoder2 = self.contracting_block(64, 128)\n",
    "        self.encoder3 = self.contracting_block(128, 256)\n",
    "        self.encoder4 = self.contracting_block(256, 512)\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder4 = self.expansive_block(512, 256)\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder3 = self.expansive_block(256, 128)\n",
    "        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder2 = self.expansive_block(128, 64)\n",
    "        self.decoder1 = self.final_block(64, out_channels)\n",
    "\n",
    "    def contracting_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=3, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def expansive_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=3, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def final_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=3, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=1, in_channels=out_channels, out_channels=out_channels),\n",
    "            nn.Sigmoid()  # Adiciona ativa√ß√£o sigmoid para garantir que a sa√≠da fique entre [0, 1]\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def crop_and_concat(self, upsampled, bypass):\n",
    "        _, _, H, W = upsampled.size()\n",
    "        _, _, H_b, W_b = bypass.size()\n",
    "        if H_b != H or W_b != W:\n",
    "            bypass = nn.functional.interpolate(bypass, size=(H, W), mode='bilinear', align_corners=True)\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(nn.functional.max_pool2d(enc1, kernel_size=2, stride=2))\n",
    "        enc3 = self.encoder3(nn.functional.max_pool2d(enc2, kernel_size=2, stride=2))\n",
    "        enc4 = self.encoder4(nn.functional.max_pool2d(enc3, kernel_size=2, stride=2))\n",
    "\n",
    "        # Decoder path\n",
    "        dec4 = self.crop_and_concat(self.upconv4(enc4), enc3)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.crop_and_concat(self.upconv3(dec4), enc2)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.crop_and_concat(self.upconv2(dec3), enc1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.decoder1(dec2)\n",
    "\n",
    "        return dec1, enc1, enc2, enc3, enc4  # Retorna tanto a imagem reconstru√≠da quanto as features do encoder\n",
    "\n",
    "def apply_pca_and_reconstruct(features, pca):\n",
    "    # Flatten the features while keeping track of the original shape\n",
    "    batch_size, channels, height, width = features.size()\n",
    "    flattened_features = features.view(batch_size, -1).cpu().numpy()\n",
    "\n",
    "    # Verifica as dimens√µes originais das features\n",
    "    original_num_features = flattened_features.shape[1]\n",
    "    print(f\"Original number of features before PCA: {original_num_features}\")\n",
    "\n",
    "    # Apply PCA projection and reconstruction\n",
    "    projected_features = pca.transform(flattened_features)\n",
    "    num_pca_components = projected_features.shape[1]\n",
    "    print(f\"Number of components after PCA: {num_pca_components}\")\n",
    "\n",
    "    reconstructed_features = pca.inverse_transform(projected_features)\n",
    "    #print(f\"Reconstructed feature dimensions (after inverse PCA): {reconstructed_features.shape}\")\n",
    "\n",
    "    # Convert back to tensor and reshape to the original feature shape\n",
    "    reconstructed_features = torch.tensor(reconstructed_features, dtype=torch.float32).view(batch_size, channels, height, width).to(device)\n",
    "\n",
    "    return reconstructed_features\n",
    "\n",
    "# Fun√ß√£o para treinar e aplicar PCA nas features extra√≠das da U-Net com verifica√ß√£o de vari√¢ncia explicada\n",
    "def train_unet_and_apply_pca(unet, data_loader, num_epochs=5):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(unet.parameters(), lr=0.0001)\n",
    "\n",
    "    global pca_train_features\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        unet.train()\n",
    "        epoch_loss = 0\n",
    "        for images, in data_loader:\n",
    "            images = images.to(device).float()\n",
    "            images /= 255.0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through U-Net to get features\n",
    "            reconstructed_images, _, _, _, unet_features = unet(images)\n",
    "\n",
    "            # Flatten and collect features for PCA training (in the first epoch)\n",
    "            if epoch == 0:\n",
    "                flattened_features = unet_features.view(images.shape[0], -1).detach().cpu().numpy()\n",
    "                if 'pca_train_features' not in globals():\n",
    "                    pca_train_features = flattened_features\n",
    "                else:\n",
    "                    pca_train_features = np.vstack((pca_train_features, flattened_features))\n",
    "\n",
    "            loss = criterion(reconstructed_images, images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(data_loader):.4f}')\n",
    "\n",
    "    # Calcula e exibe o n√∫mero de features antes do PCA\n",
    "    original_feature_count = pca_train_features.shape[1]\n",
    "    print(f\"Original number of features before PCA: {original_feature_count}\")\n",
    "\n",
    "    # Aplicando o PCA e mostrando a vari√¢ncia explicada\n",
    "    pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "    pca.fit(pca_train_features)\n",
    "    print(f\"Explained variance by PCA components: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Number of components chosen by PCA: {pca.n_components_}\")\n",
    "\n",
    "    return pca\n",
    "\n",
    "# Inicializa√ß√£o do modelo UNet\n",
    "unet = UNet().to(device)\n",
    "\n",
    "# Dicion√°rio para armazenar o PCA de cada categoria\n",
    "pca_dict = {}\n",
    "\n",
    "# Defina o DataLoader aqui\n",
    "categories = centralized_images_by_category.keys()\n",
    "\n",
    "for category in categories:\n",
    "    images = centralized_images_by_category[category]\n",
    "\n",
    "    # Adiciona a dimens√£o do canal e cria o DataLoader\n",
    "    images = np.expand_dims(images, axis=1)  # Adiciona dimens√£o do canal\n",
    "    dataset = TensorDataset(torch.tensor(images, dtype=torch.float32))\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # Treina o modelo U-Net e coleta features para o PCA\n",
    "    pca = train_unet_and_apply_pca(unet, loader, num_epochs=5)\n",
    "\n",
    "    # Armazena o PCA no dicion√°rio para a categoria atual\n",
    "    pca_dict[category] = pca\n",
    "\n",
    "    # Avalia e visualiza algumas imagens reconstru√≠das com PCA aplicado nas features\n",
    "    unet.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(3):  # Exibe 3 imagens de cada categoria\n",
    "            image = centralized_images_by_category[category][i]\n",
    "            image_tensor = torch.tensor(image / 255.0).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "            # Processa com UNet e extrai features\n",
    "            reconstructed_image, enc1, enc2, enc3, unet_features = unet(image_tensor)\n",
    "\n",
    "            # Aplica PCA nas features e reconstr√≥i as features\n",
    "            reconstructed_features = apply_pca_and_reconstruct(unet_features, pca)\n",
    "\n",
    "            # Passa as features reconstru√≠das pelo caminho de decodifica√ß√£o da U-Net\n",
    "            dec4 = unet.crop_and_concat(unet.upconv4(reconstructed_features), enc3)\n",
    "            dec4 = unet.decoder4(dec4)\n",
    "            dec3 = unet.crop_and_concat(unet.upconv3(dec4), enc2)\n",
    "            dec3 = unet.decoder3(dec3)\n",
    "            dec2 = unet.crop_and_concat(unet.upconv2(dec3), enc1)\n",
    "            dec2 = unet.decoder2(dec2)\n",
    "\n",
    "            # Corrige o n√∫mero de canais esperados pela √∫ltima camada de convolu√ß√£o\n",
    "            final_reconstructed_image = unet.decoder1(dec2)\n",
    "\n",
    "            # Converte o tensor para numpy para visualiza√ß√£o\n",
    "            final_reconstructed_image_np = final_reconstructed_image.squeeze().cpu().numpy()\n",
    "\n",
    "            # Visualiza as imagens\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.title(f'Original {category} Image {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(final_reconstructed_image_np, cmap='gray')\n",
    "            plt.title(f'Reconstructed {category} Image {i+1} with PCA')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "# Salva o dicion√°rio de PCA para uso posterior\n",
    "print(\"PCA models saved for each category.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_test_images(test_dir, categories, image_size, input_size=(256,256)):\n",
    "    test_images_by_category = load_images_by_category(test_dir, categories, image_size)\n",
    "    test_centralized_images_by_category = {}\n",
    "\n",
    "    for category, images in test_images_by_category.items():\n",
    "        test_centralized_images = center_images(images)\n",
    "        test_centralized_images_by_category[category] = test_centralized_images\n",
    "\n",
    "    return test_centralized_images_by_category\n",
    "\n",
    "test_preprocessed_images_by_category = load_and_preprocess_test_images('images_test', y, image_size=(256,256), input_size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, images in centralized_images_by_category.items():\n",
    "    mean = check_centralization(images)\n",
    "    print(f\"Mean pixel values after centralization for category {category}: {mean}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to apply UNet with different PCA models, compute OOD scores, and visualize the first 3 results\n",
    "def compute_ood_and_visualize(unet, pca_dict, test_images_by_category):\n",
    "    unet.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Dictionary to store OOD scores for each test category and PCA category\n",
    "    ood_scores_by_category = {}\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "        for test_category, test_images in test_images_by_category.items():\n",
    "            print(f\"Processing test category: {test_category}\")\n",
    "\n",
    "            # Store OOD scores for this test category\n",
    "            ood_scores_by_category[test_category] = {}\n",
    "\n",
    "            # Iterate over PCA models from different categories\n",
    "            for pca_category in pca_dict.keys():\n",
    "                ood_scores_by_category[test_category][pca_category] = []\n",
    "\n",
    "                # Process all test images in this category\n",
    "                for i, image in enumerate(test_images):\n",
    "                    image_tensor = torch.tensor(image / 255.0).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "                    # Forward pass through UNet to get features\n",
    "                    reconstructed_image, enc1, enc2, enc3, unet_features = unet(image_tensor)\n",
    "\n",
    "                    # Apply PCA to the features and reconstruct them\n",
    "                    reconstructed_features = apply_pca_and_reconstruct(unet_features, pca_dict[pca_category])\n",
    "\n",
    "                    # Calculate residuals\n",
    "                    residuals = unet_features - reconstructed_features\n",
    "\n",
    "                    # Calculate norms for OOD score\n",
    "                    norm_residuals = torch.norm(residuals)\n",
    "                    norm_original = torch.norm(unet_features)\n",
    "\n",
    "                    # Compute OOD score\n",
    "                    ood_score = (norm_residuals / norm_original).item()\n",
    "                    ood_scores_by_category[test_category][pca_category].append(ood_score)\n",
    "\n",
    "                    # Only plot the reconstruction for the first 3 images in each category\n",
    "                    if i < 3:\n",
    "                        # Pass the reconstructed features through the decoder of the UNet\n",
    "                        dec4 = unet.crop_and_concat(unet.upconv4(reconstructed_features), enc3)\n",
    "                        dec4 = unet.decoder4(dec4)\n",
    "                        dec3 = unet.crop_and_concat(unet.upconv3(dec4), enc2)\n",
    "                        dec3 = unet.decoder3(dec3)\n",
    "                        dec2 = unet.crop_and_concat(unet.upconv2(dec3), enc1)\n",
    "                        dec2 = unet.decoder2(dec2)\n",
    "                        final_reconstructed_image = unet.decoder1(dec2)\n",
    "\n",
    "                        # Convert the tensor to numpy for visualization\n",
    "                        final_reconstructed_image_np = final_reconstructed_image.squeeze().cpu().numpy()\n",
    "\n",
    "                        # Plot original and reconstructed images\n",
    "                        plt.figure(figsize=(10, 5))\n",
    "                        plt.subplot(1, 2, 1)\n",
    "                        plt.imshow(image, cmap='gray')\n",
    "                        plt.title(f'Original {test_category} Image {i+1}')\n",
    "                        plt.axis('off')\n",
    "\n",
    "                        plt.subplot(1, 2, 2)\n",
    "                        plt.imshow(final_reconstructed_image_np, cmap='gray')\n",
    "                        plt.title(f'Reconstructed {test_category} Image {i+1} with {pca_category} PCA')\n",
    "                        plt.axis('off')\n",
    "\n",
    "                        plt.show()\n",
    "\n",
    "    # Calculate average OOD score for each category with each PCA\n",
    "    avg_ood_scores_by_category = {}\n",
    "\n",
    "    for test_category, pca_ood_scores in ood_scores_by_category.items():\n",
    "        avg_ood_scores_by_category[test_category] = {}\n",
    "        for pca_category, ood_scores in pca_ood_scores.items():\n",
    "            avg_ood_score = np.mean(ood_scores)\n",
    "            avg_ood_scores_by_category[test_category][pca_category] = avg_ood_score\n",
    "            print(f\"Average OOD Score for {test_category} with {pca_category} PCA: {avg_ood_score}\")\n",
    "\n",
    "    return avg_ood_scores_by_category\n",
    "\n",
    "# Assuming you have already trained your U-Net and saved the PCA models for each category:\n",
    "avg_ood_scores_by_category = compute_ood_and_visualize(unet, pca_dict, test_preprocessed_images_by_category)\n",
    "\n",
    "# Print the average OOD scores for all categories\n",
    "for test_category, pca_ood_scores in avg_ood_scores_by_category.items():\n",
    "    print(f\"\\nAverage OOD Scores for test category '{test_category}':\")\n",
    "    for pca_category, avg_ood in pca_ood_scores.items():\n",
    "        print(f\"  PCA from '{pca_category}' => Average OOD Score: {avg_ood}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import torch\n",
    "\n",
    "# Function to project features onto selected PCA components and transform back\n",
    "def project_and_transform_back(data, pca, specific_indices):\n",
    "    \"\"\"\n",
    "    Project the data onto specific PCA components, reconstruct the data, and calculate residuals and OOD score.\n",
    "    \"\"\"\n",
    "    # Flatten the features for PCA projection\n",
    "    flattened_data = data.view(1, -1).cpu().numpy()\n",
    "    \n",
    "    # Project onto the PCA components\n",
    "    projected = pca.transform(flattened_data)\n",
    "    \n",
    "    # Use only the specific components\n",
    "    projected_specific = projected[:, specific_indices]\n",
    "    \n",
    "    # Reconstruct the data from the selected components\n",
    "    specific_components = pca.components_[specific_indices]\n",
    "    reconstructed_data = np.dot(projected_specific, specific_components)\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals = flattened_data - reconstructed_data\n",
    "    \n",
    "    # Calculate norms for OOD score\n",
    "    norm_residuals = np.linalg.norm(residuals)\n",
    "    norm_original = np.linalg.norm(flattened_data)\n",
    "    \n",
    "    # Calculate OOD score as the ratio of the norms\n",
    "    ood_score = norm_residuals / norm_original\n",
    "    \n",
    "    return reconstructed_data, residuals, ood_score\n",
    "def compute_ood_with_selected_components(unet, pca_dict, test_images_by_category):\n",
    "    unet.eval()  # Set UNet to evaluation mode\n",
    "    \n",
    "    # Dictionary to store OOD scores for each test category and PCA category\n",
    "    ood_scores_by_category = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for test_category, test_images in test_images_by_category.items():\n",
    "            print(f\"Processing test category: {test_category}\")\n",
    "\n",
    "            ood_scores_by_category[test_category] = {}\n",
    "\n",
    "            # Iterate over PCA models from different categories\n",
    "            for pca_category, pca in pca_dict.items():\n",
    "                print(f\"Processing with PCA from category: {pca_category}\")\n",
    "                ood_scores_by_category[test_category][pca_category] = []\n",
    "\n",
    "                # Retrieve explained variance ratio and components from the PCA object\n",
    "                explained_variance_ratio = pca.explained_variance_ratio_\n",
    "                components = pca.components_\n",
    "\n",
    "                all_selected_indices = []\n",
    "\n",
    "                # Process each image in the test category\n",
    "                for i, image in enumerate(test_images):\n",
    "                    # Prepare image tensor and extract UNet features\n",
    "                    image_tensor = torch.tensor(image / 255.0).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "                    reconstructed_image, enc1, enc2, enc3, unet_features = unet(image_tensor)\n",
    "\n",
    "                    # Flatten UNet features for PCA projection\n",
    "                    flattened_features = unet_features.view(1, -1).cpu().numpy()\n",
    "\n",
    "                    # Project and select PCA components\n",
    "                    norms_category = np.linalg.norm(components, axis=1)\n",
    "                    selected_indices = np.where(np.cumsum(explained_variance_ratio) <= 0.9)[0]\n",
    "                    all_selected_indices.append(selected_indices)\n",
    "\n",
    "                # Aggregate selected components across all images\n",
    "                aggregated_selected_indices = np.unique(np.concatenate(all_selected_indices))\n",
    "\n",
    "                # Skip processing if no valid components are selected\n",
    "                if len(aggregated_selected_indices) == 0:\n",
    "                    print(f\"Warning: No valid components selected for {test_category} with {pca_category} PCA. Skipping this combination.\")\n",
    "                    continue\n",
    "\n",
    "                # Process each image again using selected components for projection, reconstruction, and OOD calculation\n",
    "                for i, image in enumerate(test_images):\n",
    "                    image_tensor = torch.tensor(image / 255.0).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "                    reconstructed_image, enc1, enc2, enc3, unet_features = unet(image_tensor)\n",
    "\n",
    "                    # Project and reconstruct features using only the selected PCA components\n",
    "                    reconstructed_features, residuals, ood_score = project_and_transform_back(unet_features, pca, aggregated_selected_indices)\n",
    "\n",
    "                    # Reshape the residuals to the same shape as `unet_features`\n",
    "                    residuals_reshaped = residuals.reshape(unet_features.shape)  # Reshape to (B, C, H, W)\n",
    "\n",
    "                    # Append the OOD score\n",
    "                    ood_scores_by_category[test_category][pca_category].append(ood_score)\n",
    "\n",
    "                    # Visualize the first 3 images with their reconstructions and residuals\n",
    "                    if i < 3:\n",
    "                        # Pass the reconstructed features through the decoder of the UNet\n",
    "                        dec4 = unet.crop_and_concat(unet.upconv4(torch.tensor(reconstructed_features, dtype=torch.float32).view_as(unet_features).to(device)), enc3)\n",
    "                        dec4 = unet.decoder4(dec4)\n",
    "                        dec3 = unet.crop_and_concat(unet.upconv3(dec4), enc2)\n",
    "                        dec3 = unet.decoder3(dec3)\n",
    "                        dec2 = unet.crop_and_concat(unet.upconv2(dec3), enc1)\n",
    "                        dec2 = unet.decoder2(dec2)\n",
    "                        final_reconstructed_image = unet.decoder1(dec2)\n",
    "\n",
    "                        # Convert to numpy for visualization\n",
    "                        final_reconstructed_image_np = final_reconstructed_image.squeeze().cpu().numpy()\n",
    "\n",
    "                        # Convert residuals to numpy for visualization\n",
    "                        residuals_np = residuals_reshaped.squeeze()  # Residuals are already in NumPy format\n",
    "\n",
    "                        # Plot original, reconstructed, and residual images\n",
    "                        plt.figure(figsize=(15, 5))\n",
    "                        plt.subplot(1, 3, 1)\n",
    "                        plt.imshow(image, cmap='gray')\n",
    "                        plt.title(f'Original {test_category} Image {i+1}')\n",
    "                        plt.axis('off')\n",
    "\n",
    "                        plt.subplot(1, 3, 2)\n",
    "                        plt.imshow(final_reconstructed_image_np, cmap='gray')\n",
    "                        plt.title(f'Reconstructed {test_category} Image {i+1} with {pca_category} PCA')\n",
    "                        plt.axis('off')\n",
    "\n",
    "                        plt.subplot(1, 3, 3)\n",
    "                        plt.imshow(residuals_np[0], cmap='gray')  # Select the first channel for visualization\n",
    "                        plt.title(f'Residuals {test_category} Image {i+1} with {pca_category} PCA')\n",
    "                        plt.axis('off')\n",
    "\n",
    "                        plt.show()\n",
    "\n",
    "    # Calculate average OOD score for each category and PCA\n",
    "    avg_ood_scores_by_category = {}\n",
    "    for test_category, pca_ood_scores in ood_scores_by_category.items():\n",
    "        avg_ood_scores_by_category[test_category] = {}\n",
    "        for pca_category, ood_scores in pca_ood_scores.items():\n",
    "            avg_ood_score = np.mean(ood_scores)\n",
    "            avg_ood_scores_by_category[test_category][pca_category] = avg_ood_score\n",
    "            print(f\"Average OOD Score for {test_category} with {pca_category} PCA: {avg_ood_score}\")\n",
    "\n",
    "    return avg_ood_scores_by_category\n",
    "\n",
    "# Assuming you have already trained your U-Net and saved the PCA models for each category\n",
    "avg_ood_scores_by_category = compute_ood_with_selected_components(unet, pca_dict, test_preprocessed_images_by_category)\n",
    "\n",
    "# Print the average OOD scores for all categories\n",
    "for test_category, pca_ood_scores in avg_ood_scores_by_category.items():\n",
    "    print(f\"\\nAverage OOD Scores for test category '{test_category}':\")\n",
    "    for pca_category, avg_ood in pca_ood_scores.items():\n",
    "        print(f\"  PCA from '{pca_category}' => Average OOD Score: {avg_ood}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['image_path'].tolist()\n",
    "y = df['category'].tolist()\n",
    "unique_categories = list(df['category'].unique())\n",
    "print(f\"Unique categories: {unique_categories}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "standard_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_images_set(X_train, X_test, y_train, y_test, output_dir_train='images_train', output_dir_test='images_test', standard_size=standard_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_training_preprocessed_images_by_category = load_and_preprocess_test_images('images_train', y, image_size=(256,256), input_size=(256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Verifica o dispositivo dispon√≠vel (GPU ou CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "\n",
    "# Define o modelo UNet para codificar e decodificar\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder1 = self.contracting_block(in_channels, 64)\n",
    "        self.encoder2 = self.contracting_block(64, 128)\n",
    "        self.encoder3 = self.contracting_block(128, 256)\n",
    "        self.encoder4 = self.contracting_block(256, 512)\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.decoder4 = self.expansive_block(512, 256)\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder3 = self.expansive_block(256, 128)\n",
    "        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder2 = self.expansive_block(128, 64)\n",
    "        self.decoder1 = self.final_block(64, out_channels)\n",
    "\n",
    "    def contracting_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=3, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def expansive_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=3, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def final_block(self, in_channels, out_channels):\n",
    "        block = nn.Sequential(\n",
    "            nn.Conv2d(kernel_size=3, in_channels=in_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=3, in_channels=out_channels, out_channels=out_channels, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(kernel_size=1, in_channels=out_channels, out_channels=out_channels),\n",
    "            nn.Sigmoid()  # Adiciona ativa√ß√£o sigmoid para garantir que a sa√≠da fique entre [0, 1]\n",
    "        )\n",
    "        return block\n",
    "\n",
    "    def crop_and_concat(self, upsampled, bypass):\n",
    "        _, _, H, W = upsampled.size()\n",
    "        _, _, H_b, W_b = bypass.size()\n",
    "        if H_b != H or W_b != W:\n",
    "            bypass = nn.functional.interpolate(bypass, size=(H, W), mode='bilinear', align_corners=True)\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder path\n",
    "        enc1 = self.encoder1(x)\n",
    "        enc2 = self.encoder2(nn.functional.max_pool2d(enc1, kernel_size=2, stride=2))\n",
    "        enc3 = self.encoder3(nn.functional.max_pool2d(enc2, kernel_size=2, stride=2))\n",
    "        enc4 = self.encoder4(nn.functional.max_pool2d(enc3, kernel_size=2, stride=2))\n",
    "\n",
    "        # Decoder path\n",
    "        dec4 = self.crop_and_concat(self.upconv4(enc4), enc3)\n",
    "        dec4 = self.decoder4(dec4)\n",
    "        dec3 = self.crop_and_concat(self.upconv3(dec4), enc2)\n",
    "        dec3 = self.decoder3(dec3)\n",
    "        dec2 = self.crop_and_concat(self.upconv2(dec3), enc1)\n",
    "        dec2 = self.decoder2(dec2)\n",
    "        dec1 = self.decoder1(dec2)\n",
    "\n",
    "        return dec1, enc1, enc2, enc3, enc4  # Retorna tanto a imagem reconstru√≠da quanto as features do encoder\n",
    "\n",
    "def apply_pca_and_reconstruct(features, pca):\n",
    "    # Flatten the features while keeping track of the original shape\n",
    "    batch_size, channels, height, width = features.size()\n",
    "    flattened_features = features.view(batch_size, -1).cpu().numpy()\n",
    "\n",
    "    # Verifica as dimens√µes originais das features\n",
    "    original_num_features = flattened_features.shape[1]\n",
    "    print(f\"Original number of features before PCA: {original_num_features}\")\n",
    "\n",
    "    # Apply PCA projection and reconstruction\n",
    "    projected_features = pca.transform(flattened_features)\n",
    "    num_pca_components = projected_features.shape[1]\n",
    "    print(f\"Number of components after PCA: {num_pca_components}\")\n",
    "\n",
    "    reconstructed_features = pca.inverse_transform(projected_features)\n",
    "    #print(f\"Reconstructed feature dimensions (after inverse PCA): {reconstructed_features.shape}\")\n",
    "\n",
    "    # Convert back to tensor and reshape to the original feature shape\n",
    "    reconstructed_features = torch.tensor(reconstructed_features, dtype=torch.float32).view(batch_size, channels, height, width).to(device)\n",
    "\n",
    "    return reconstructed_features\n",
    "\n",
    "# Fun√ß√£o para treinar e aplicar PCA nas features extra√≠das da U-Net com verifica√ß√£o de vari√¢ncia explicada\n",
    "def train_unet_and_apply_pca(unet, data_loader, num_epochs=5):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(unet.parameters(), lr=0.0001)\n",
    "\n",
    "    global pca_train_features\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        unet.train()\n",
    "        epoch_loss = 0\n",
    "        for images, in data_loader:\n",
    "            images = images.to(device).float()\n",
    "            images /= 255.0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass through U-Net to get features\n",
    "            reconstructed_images, _, _, _, unet_features = unet(images)\n",
    "\n",
    "            # Flatten and collect features for PCA training (in the first epoch)\n",
    "            if epoch == 0:\n",
    "                flattened_features = unet_features.view(images.shape[0], -1).detach().cpu().numpy()\n",
    "                if 'pca_train_features' not in globals():\n",
    "                    pca_train_features = flattened_features\n",
    "                else:\n",
    "                    pca_train_features = np.vstack((pca_train_features, flattened_features))\n",
    "\n",
    "            loss = criterion(reconstructed_images, images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss/len(data_loader):.4f}')\n",
    "\n",
    "    # Calcula e exibe o n√∫mero de features antes do PCA\n",
    "    original_feature_count = pca_train_features.shape[1]\n",
    "    print(f\"Original number of features before PCA: {original_feature_count}\")\n",
    "\n",
    "    # Aplicando o PCA e mostrando a vari√¢ncia explicada\n",
    "    pca = PCA(n_components=0.95)  # Retain 95% variance\n",
    "    pca.fit(pca_train_features)\n",
    "    print(f\"Explained variance by PCA components: {pca.explained_variance_ratio_}\")\n",
    "    print(f\"Number of components chosen by PCA: {pca.n_components_}\")\n",
    "\n",
    "    return pca\n",
    "\n",
    "# Inicializa√ß√£o do modelo UNet\n",
    "unet = UNet().to(device)\n",
    "\n",
    "# Dicion√°rio para armazenar o PCA de cada categoria\n",
    "pca_dict = {}\n",
    "\n",
    "# Defina o DataLoader aqui\n",
    "categories = centralized_images_by_category.keys()\n",
    "\n",
    "for category in categories:\n",
    "    images = centralized_images_by_category[category]\n",
    "\n",
    "    # Adiciona a dimens√£o do canal e cria o DataLoader\n",
    "    images = np.expand_dims(images, axis=1)  # Adiciona dimens√£o do canal\n",
    "    dataset = TensorDataset(torch.tensor(images, dtype=torch.float32))\n",
    "    loader = DataLoader(dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "    # Treina o modelo U-Net e coleta features para o PCA\n",
    "    pca = train_unet_and_apply_pca(unet, loader, num_epochs=5)\n",
    "\n",
    "    # Armazena o PCA no dicion√°rio para a categoria atual\n",
    "    pca_dict[category] = pca\n",
    "\n",
    "    # Avalia e visualiza algumas imagens reconstru√≠das com PCA aplicado nas features\n",
    "    unet.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(3):  # Exibe 3 imagens de cada categoria\n",
    "            image = centralized_images_by_category[category][i]\n",
    "            image_tensor = torch.tensor(image / 255.0).unsqueeze(0).unsqueeze(0).float().to(device)\n",
    "\n",
    "            # Processa com UNet e extrai features\n",
    "            reconstructed_image, enc1, enc2, enc3, unet_features = unet(image_tensor)\n",
    "\n",
    "            # Aplica PCA nas features e reconstr√≥i as features\n",
    "            reconstructed_features = apply_pca_and_reconstruct(unet_features, pca)\n",
    "\n",
    "            # Passa as features reconstru√≠das pelo caminho de decodifica√ß√£o da U-Net\n",
    "            dec4 = unet.crop_and_concat(unet.upconv4(reconstructed_features), enc3)\n",
    "            dec4 = unet.decoder4(dec4)\n",
    "            dec3 = unet.crop_and_concat(unet.upconv3(dec4), enc2)\n",
    "            dec3 = unet.decoder3(dec3)\n",
    "            dec2 = unet.crop_and_concat(unet.upconv2(dec3), enc1)\n",
    "            dec2 = unet.decoder2(dec2)\n",
    "\n",
    "            # Corrige o n√∫mero de canais esperados pela √∫ltima camada de convolu√ß√£o\n",
    "            final_reconstructed_image = unet.decoder1(dec2)\n",
    "\n",
    "            # Converte o tensor para numpy para visualiza√ß√£o\n",
    "            final_reconstructed_image_np = final_reconstructed_image.squeeze().cpu().numpy()\n",
    "\n",
    "            # Visualiza as imagens\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.subplot(1, 2, 1)\n",
    "            plt.imshow(image, cmap='gray')\n",
    "            plt.title(f'Original {category} Image {i+1}')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.imshow(final_reconstructed_image_np, cmap='gray')\n",
    "            plt.title(f'Reconstructed {category} Image {i+1} with PCA')\n",
    "            plt.axis('off')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "# Salva o dicion√°rio de PCA para uso posterior\n",
    "print(\"PCA models saved for each category.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
