{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéâ Out-of-Distribution (OOD) with PCA in Image Processing\n",
    "\n",
    "The goal of this notebook is to understand the depths of using Principal Component Analysis in order to perform OOD tasks in the domain of image processing.\n",
    "\n",
    "## üìù Plan of action\n",
    "\n",
    "### ‚ôªÔ∏è Preprocessing phase\n",
    "\n",
    "In order to achieve our goal, we need to understand how the dataset is structured.\n",
    "\n",
    "For this notebook, we are going to use the CBIR 15 dataset, that contains images of different places, such as an office, a bedroom, a mountain, etc. Note that there are some places that are similar one to another, i.e. a bedroom and a living room.\n",
    "\n",
    "Thus, in order to extract the features of the images we have to preprocess those images:\n",
    "\n",
    "- Get the images that are located in data/CBIR_15-scene and fit them to a dataframe using Pandas\n",
    "  - Locate the \"Labels.txt\" file: it shows where the indexes of the images from each category starts\n",
    "- Create the dataset with this information with two columns: the path to the image and its category\n",
    "- Transform all of the images in the same size (in this case, we are going with 256x256)\n",
    "  \n",
    "Now, in order to extract the features, it's necessary to divide the reshaped images into patches of 32x32 pixels. This is good to perform processing tasks to avoid waiting long periods of time.\n",
    "\n",
    "After all the preprocess, we should separate the images into two different foldes: one contains the patches of the training images that is going to give us their principal components and dimensions, and the other is the patches of the test images, that is going to be tested to fit into those dimensions and we'll get an OOD score afterwards.\n",
    "\n",
    "### üèãüèΩ‚Äç‚ôÇÔ∏è Training phase\n",
    "\n",
    "With the images that are stored inside the \"patches_train\" folder, the first thing we are going to do is _normalize_ all of the images to find the correct maximum covariance and transforming all the variables into the same scale.\n",
    "\n",
    "Next, we should then apply the PCA with all the components. As we have patches of 32x32, we'll be having 1024 features, hence components. Then we plot a graph to see how many components truly contributes for the most variance of the data - and give us more information about it. We're going to take the threshold of 95% of variance in this notebook.\n",
    "\n",
    "After getting the PCA with components that describe 95% of the variance, it's time to test our images and see how far of the residual space their data can be found.\n",
    "\n",
    "### ‚öóÔ∏è Test phase and results\n",
    "\n",
    "In this phase, we take the test images and normalize then with the same scale of each PCA. This is important to maintain consistency throughout the final results and measure the norms in the new dimension properly.\n",
    "\n",
    "After that, we calculate the norm of the projection of the given data into the orthogonal space of the principal component and divide it by the norm of the data in relation to the origin. This is the OOD score.\n",
    "\n",
    "We calculate the mean of the score for each category and get the minimal one. The current environment is the smallest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "First of all, we need to understand which libraries we are going to use:\n",
    "\n",
    "- os: Deals with the operation system interface such as finding the relative and absolute path of files inside a project and reading/writing files for example.\n",
    "- sys: This module provides access to some variables used or maintained by the interpreter and to functions that interact strongly with the interpreter.\n",
    "- numpy: NumPy is the fundamental package for scientific computing in Python. It is a Python library that provides a multidimensional array object, various derived objects (such as masked arrays and matrices), and an assortment of routines for fast operations on arrays, including mathematical, logical, shape manipulation, sorting, selecting, I/O, discrete Fourier transforms, basic linear algebra, basic statistical operations, random simulation and much more.\n",
    "- pandas: Pandas is an open source, BSD-licensed library providing high-performance, easy-to-use data structures and data analysis tools for the Python programming language.\n",
    "- matplotlib: Deals with plotting graphs to visualize data in a graphical way.\n",
    "- sklearn: Scikit-learn provides dozens of built-in machine learning algorithms and models, called estimators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'd suggest to use a conda virtual environment in order to avoid messing up your base kernel environment and causing dependency errors in the future.\n",
    "\n",
    "After you successfully installed all the modules, it's time to import our custom modules that are going to deal with:\n",
    "\n",
    "- Creation of our dataframe using pandas\n",
    "- Separation of our dataset into patches of 32x32 in folders of training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from dataframe_generator import *\n",
    "from image_patching import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "\n",
    "def extract_tgz(tgz_path, extract_to):\n",
    "    if not os.path.exists(extract_to):\n",
    "        os.makedirs(extract_to)\n",
    "    \n",
    "    with tarfile.open(tgz_path, 'r:gz') as tar:\n",
    "        tar.extractall(path=extract_to)\n",
    "        print(f\"Arquivos extra√≠dos para {extract_to}\")\n",
    "\n",
    "tgz_path = '../CBIR_15-Scene.tgz'\n",
    "extract_to = '../data/'\n",
    "\n",
    "extract_tgz(tgz_path, extract_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_dataframe()\n",
    "patch_size = (32,32)\n",
    "standard_size = (256, 256)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚òùÔ∏è Part I: Comparing two different environments\n",
    "\n",
    "### ‚ôªÔ∏è Preprocessing phase\n",
    "\n",
    "Now we start our experiments to understand if our idea work, however this time we are going to understand what happens with our approach using two different environments.\n",
    "\n",
    "In our case, I'm going to take the **Coast** and **Office** environments arbitrarily.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categories = ['Coast', 'Office']\n",
    "\n",
    "df_different = df[df['category'].isin(train_categories)]\n",
    "df_different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to separate our dataset into train and test. We should use the built-in function of sklearn to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_different['image_path']\n",
    "y = df_different['category']\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making sure that everything went well, we plot the grid of all the patches from the first image of our training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_patches_grid(patches, patch_size, grid_shape):\n",
    "    fig, axes = plt.subplots(grid_shape[0], grid_shape[1], figsize=(10, 10))\n",
    "    patch_idx = 0\n",
    "    for i in range(grid_shape[0]):\n",
    "        for j in range(grid_shape[1]):\n",
    "            if patch_idx < len(patches):\n",
    "                axes[i, j].imshow(cv2.cvtColor(patches[patch_idx], cv2.COLOR_BGR2RGB))\n",
    "                axes[i, j].axis('off')\n",
    "                patch_idx += 1\n",
    "            else:\n",
    "                axes[i, j].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "patch_size = (32,32)\n",
    "standard_size = (256, 256)\n",
    "\n",
    "first_image_path = X_train.iloc[0]\n",
    "image = cv2.imread(first_image_path)\n",
    "resized_image = resize_image(image, standard_size)\n",
    "patches, positions = create_patches(resized_image, patch_size)\n",
    "\n",
    "grid_rows = resized_image.shape[0] // patch_size[0]\n",
    "grid_cols = resized_image.shape[1] // patch_size[1]\n",
    "\n",
    "plot_patches_grid(patches, patch_size, (grid_rows, grid_cols))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is exactly what the module that's inside our \"image_patching.py\" do. So we now, need to save everything into the subfolders by calling that function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_images_set(X_train, X_test, y_train, y_test, patch_size, output_dir_train='patches_train', output_dir_test='patches_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patches_by_category(base_dir, categories):\n",
    "    patches_by_category = {}\n",
    "    \n",
    "    for category in categories:\n",
    "        category_patches = {}\n",
    "        category_dir = os.path.join(base_dir, str(category))\n",
    "        \n",
    "        for root, _, files in os.walk(category_dir):\n",
    "            files = [f for f in files if f.endswith('.png') and '_patch_' in f]\n",
    "            files = sorted(files, key=lambda x: (int(x.split('_')[1]), int(x.split('_')[3]), int(x.split('_')[4].split('.')[0])))\n",
    "\n",
    "            for filename in files:\n",
    "                try:\n",
    "                    parts = filename.split('_')\n",
    "                    image_id = int(parts[1])\n",
    "                    y = int(parts[3])\n",
    "                    x = int(parts[4].split('.')[0])\n",
    "                    patch = cv2.imread(os.path.join(root, filename), cv2.IMREAD_GRAYSCALE)\n",
    "                    if patch is not None:\n",
    "                        if image_id not in category_patches:\n",
    "                            category_patches[image_id] = ([], [])\n",
    "                        category_patches[image_id][0].append(patch.flatten())\n",
    "                        category_patches[image_id][1].append((y, x))\n",
    "                except (IndexError, ValueError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        patches_by_category[category] = category_patches\n",
    "    \n",
    "    return patches_by_category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should load our patches for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_patches_by_category = load_patches_by_category('patches_train', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üèãüèΩ‚Äç‚ôÇÔ∏è Training phase\n",
    "\n",
    "Now that the have our training patches stored in that variable above, we should start our analysis with PCA.\n",
    "\n",
    "First of all, we **need to normalize and center** the data. It's so importantt that I had to emphasize it. Plus, since we are dealing with different categories, each one of them should be normalized with a different scaler (and we're going to save it for later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_patches(patches):\n",
    "    return patches - patches.mean(axis=0)\n",
    "\n",
    "centered_training_patches_by_category = {}\n",
    "for category, images in training_patches_by_category.items():\n",
    "    centered_images = {}\n",
    "    for image_id, (patches, positions) in images.items():\n",
    "        centered_patches = center_patches(np.array(patches))\n",
    "        centered_images[image_id] = (centered_patches, positions)\n",
    "    centered_training_patches_by_category[category] = centered_images\n",
    "\n",
    "print(centered_training_patches_by_category['Office'][list(centered_training_patches_by_category['Office'].keys())[0]][0].shape)\n",
    "print(centered_training_patches_by_category['Coast'][list(centered_training_patches_by_category['Coast'].keys())[0]][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, images in centered_training_patches_by_category.items():\n",
    "    sorted_ids = sorted(images.keys())\n",
    "    print(f\"Sorted Image IDs for category {category}: {sorted_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def reassemble_image_from_patches(patches, positions, original_image_shape, patch_size):\n",
    "    reconstructed_image = np.zeros(original_image_shape, dtype=np.float32)\n",
    "    patch_height, patch_width = patch_size\n",
    "\n",
    "    for patch, (i, j) in zip(patches, positions):\n",
    "        if i + patch_height <= original_image_shape[0] and j + patch_width <= original_image_shape[1]:\n",
    "            patch = patch.reshape((patch_height, patch_width))\n",
    "            reconstructed_image[i:i + patch_height, j:j + patch_width] = patch\n",
    "\n",
    "    return reconstructed_image\n",
    "\n",
    "def save_reconstructed_image(reconstructed_image, save_path):\n",
    "    reconstructed_image_uint8 = np.clip(reconstructed_image, 0, 255).astype(np.uint8) #perdre d'info avec √ßa\n",
    "    cv2.imwrite(save_path, reconstructed_image_uint8)\n",
    "\n",
    "categories = [\"Coast\", \"Office\"]\n",
    "base_input_dir = \"patches_train\"\n",
    "base_output_dir = \"different_original_images_raw\"\n",
    "\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "training_patches_by_category = load_patches_by_category(base_input_dir, categories)\n",
    "\n",
    "for category, image_patches in training_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        centered_patches = center_patches(np.array(patches))\n",
    "        reconstructed_image = reassemble_image_from_patches(centered_patches, positions, original_image_shape, patch_size)\n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"reconstructed_image_{image_id}.png\")\n",
    "        save_reconstructed_image(reconstructed_image, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 214 training images for 'Office' with 64 patches each, then we should have 13696 patche in total.\n",
    "Similarly, we have 356 training images for 'Coast', we should have 22784 patches in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_distribution(patches, title):\n",
    "    if isinstance(patches, list):\n",
    "        patches = np.array(patches)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(patches.flatten(), bins=50, alpha=0.75)\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Patch value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "for category, images in training_patches_by_category.items():\n",
    "    count = 0\n",
    "    for image_id, (patches, positions) in images.items():\n",
    "        if count >= 3:\n",
    "            break\n",
    "        plot_distribution(patches, f'Original data distribution - {category} (Image ID: {image_id})')\n",
    "        centered_patches = centered_training_patches_by_category[category][image_id][0]\n",
    "        plot_distribution(centered_patches, f'Centered data distribution - {category} (Image ID: {image_id})')\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see by analysing the distributions above that the StandardScaler has successfully normalized our data between 0 and 1.\n",
    "\n",
    "Now let's find the PCA for the patches. Since each patch has 32x32 (1024) pixels, we're assuming that this is the initial number of components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_all_components_pca(patches_by_category, n_components=1024):\n",
    "    all_components_pca_by_category = {}\n",
    "    \n",
    "    for category, images in patches_by_category.items():\n",
    "        all_patches = []\n",
    "        for image_id, (patches, positions) in images.items():\n",
    "            all_patches.append(patches)\n",
    "        all_patches = np.vstack(all_patches) \n",
    "\n",
    "        if all_patches.size == 0:\n",
    "            continue\n",
    "        \n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(all_patches)\n",
    "        all_components_pca_by_category[category] = pca\n",
    "    return all_components_pca_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_reduced_pca(patches_by_category, n_components=1024, number_variance=0.95):\n",
    "    pca_by_category = {}\n",
    "    num_components_reduced_dict = {}\n",
    "    \n",
    "    for category, images in patches_by_category.items():\n",
    "        all_patches = []\n",
    "        for image_id, (patches, positions) in images.items():\n",
    "            all_patches.append(patches)\n",
    "        all_patches = np.vstack(all_patches)  \n",
    "        if all_patches.size == 0:\n",
    "            continue\n",
    "        \n",
    "        pca = PCA(n_components=n_components)\n",
    "        pca.fit(all_patches)\n",
    "        \n",
    "        cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "        num_components_reduced = np.where(cumulative_variance >= number_variance)[0][0] + 1\n",
    "        \n",
    "        pca = PCA(n_components=num_components_reduced)\n",
    "        pca.fit(all_patches)\n",
    "        \n",
    "        pca_by_category[category] = pca\n",
    "        num_components_reduced_dict[category] = num_components_reduced\n",
    "\n",
    "    min_num_components = min(num_components_reduced_dict.values())\n",
    "    return pca_by_category, num_components_reduced_dict, min_num_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_pca_components(pca_by_category, num_components_dict):\n",
    "    for category, pca in pca_by_category.items():\n",
    "        num_components = num_components_dict[category]\n",
    "        components = pca.components_\n",
    "\n",
    "        n_rows = (num_components // 20) + (1 if num_components % 20 != 0 else 0)\n",
    "        n_cols = min(num_components, 20)\n",
    "\n",
    "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, n_rows * 0.8))\n",
    "        for i, ax in enumerate(axes.flatten()):\n",
    "            if i < num_components:\n",
    "                ax.imshow(components[i].reshape(32, 32), cmap='gray')\n",
    "            ax.axis('off')\n",
    "        plt.suptitle(f'{num_components} Principal Components - Category: {category}')\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(np.log(pca.explained_variance_[:num_components]))\n",
    "        plt.title(f'Log-Variance of Principal Components - Category: {category}')\n",
    "        plt.xlabel('Index of the Principal Component')\n",
    "        plt.ylabel('Log-Variance')\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Category: \" + category)\n",
    "        print(f\"Number of components: {num_components}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_components_pca_by_category = apply_all_components_pca(centered_training_patches_by_category)\n",
    "num_components_all_dict = {category: 1024 for category in centered_training_patches_by_category}\n",
    "visualize_pca_components(all_components_pca_by_category, num_components_all_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_components_pca_by_category_95, num_components_reduced_dict_95, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.95)\n",
    "reduced_components_pca_by_category_90, num_components_reduced_dict_90, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.90)\n",
    "reduced_components_pca_by_category_85, num_components_reduced_dict_85, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.85)\n",
    "reduced_components_pca_by_category_80, num_components_reduced_dict_80, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_num_components(num_components_reduced_dict, variance_level):\n",
    "    print(f\"\\nNumber of Components for {variance_level*100}% Variance Explained:\")\n",
    "    for category, num_components in num_components_reduced_dict.items():\n",
    "        print(f\"Category: {category}, Number of Components: {num_components}\")\n",
    "\n",
    "# Imprimir o n√∫mero de componentes para cada n√≠vel de vari√¢ncia explicada\n",
    "print_num_components(num_components_reduced_dict_95, 0.95)\n",
    "print_num_components(num_components_reduced_dict_90, 0.90)\n",
    "print_num_components(num_components_reduced_dict_85, 0.85)\n",
    "print_num_components(num_components_reduced_dict_80, 0.80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now, we see that for the \"Coast\" we only need 23 from 1024 components to explain 95% of the variance in the patch. For the \"Office\", it is reduced to 22.\n",
    "\n",
    "The variable that stores the PCA is populated with the PCA that has these minimal description components number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_and_reconstruct_patches(pca_by_category, centered_patches_by_category):\n",
    "    reconstructed_patches_by_category = {}\n",
    "\n",
    "    for category, pca in pca_by_category.items():\n",
    "        images = centered_patches_by_category[category]\n",
    "        reconstructed_images = {}\n",
    "        \n",
    "        for image_id, (centered_patches, positions) in images.items():\n",
    "            projected = pca.transform(centered_patches)\n",
    "            reconstructed_patches = pca.inverse_transform(projected)\n",
    "            reconstructed_images[image_id] = (reconstructed_patches, positions)\n",
    "        \n",
    "        reconstructed_patches_by_category[category] = reconstructed_images\n",
    "    \n",
    "    return reconstructed_patches_by_category\n",
    "\n",
    "all_components_pca_by_category = apply_all_components_pca(centered_training_patches_by_category)\n",
    "\n",
    "reconstructed_patches_by_category = project_and_reconstruct_patches(all_components_pca_by_category, centered_training_patches_by_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_dir = \"different_all_components_pca_images_reconstructed\"\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "for category, image_patches in reconstructed_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        reconstructed_image = reassemble_image_from_patches(patches, positions, original_image_shape, patch_size)\n",
    "        \n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "for category, image_patches in reconstructed_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        reconstructed_image = reassemble_image_from_patches(patches, positions, original_image_shape, patch_size)\n",
    "        \n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"reconstructed_image_{image_id}.png\")\n",
    "        save_reconstructed_image(reconstructed_image, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_reconstructed_patches_by_category = project_and_reconstruct_patches(reduced_components_pca_by_category_90, centered_training_patches_by_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_dir = \"different_reduced_components_pca_images_reconstructed\"\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "for category, image_patches in reduced_reconstructed_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        reconstructed_image = reassemble_image_from_patches(patches, positions, original_image_shape, patch_size)\n",
    "        \n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"reconstructed_image_{image_id}.png\")\n",
    "        save_reconstructed_image(reconstructed_image, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check it visually, by reconstructing the images and assuring that the main features are somewhat relatable to the original image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öóÔ∏è Test phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should start our experimenting phas.\n",
    "We bein by loading the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patches_by_category = load_patches_by_category('patches_test', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Definir a categoria\n",
    "category = 'Coast'\n",
    "\n",
    "# Verificar se a categoria existe nos patches carregados\n",
    "if category in test_patches_by_category:\n",
    "    # Obter os patches da categoria\n",
    "    category_patches = test_patches_by_category[category]\n",
    "    \n",
    "    # Obter o primeiro image_id e seus patches correspondentes\n",
    "    if category_patches:\n",
    "        first_image_id = next(iter(category_patches))\n",
    "        patches, _ = category_patches[first_image_id]\n",
    "        \n",
    "        # Verificar se h√° patches\n",
    "        if patches:\n",
    "            # Definir o tamanho da grid\n",
    "            num_patches = len(patches)\n",
    "            grid_size = int(math.ceil(math.sqrt(num_patches)))\n",
    "            patch_size = int(len(patches[0]) ** 0.5)  # Assumindo que o patch √© quadrado\n",
    "            \n",
    "            # Criar uma figura com subplots para a grid\n",
    "            fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))\n",
    "            fig.suptitle(f'Patches da primeira imagem da categoria: {category}')\n",
    "            \n",
    "            # Preencher a grid com os patches\n",
    "            for i in range(grid_size):\n",
    "                for j in range(grid_size):\n",
    "                    patch_idx = i * grid_size + j\n",
    "                    if patch_idx < num_patches:\n",
    "                        patch = patches[patch_idx]\n",
    "                        axes[i, j].imshow(patch.reshape(patch_size, patch_size), cmap='gray')\n",
    "                    axes[i, j].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Nenhum patch encontrado na primeira imagem.\")\n",
    "    else:\n",
    "        print(\"Nenhuma imagem encontrada nessa categoria.\")\n",
    "else:\n",
    "    print(f\"Categoria '{category}' n√£o encontrada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_test_patches_by_category = {}\n",
    "\n",
    "for category, images in test_patches_by_category.items():\n",
    "    centered_images = {}\n",
    "    for image_id, (patches, positions) in images.items():\n",
    "        centered_patches = center_patches(np.array(patches))\n",
    "        centered_images[image_id] = (centered_patches, positions)\n",
    "    \n",
    "    centered_test_patches_by_category[category] = centered_images\n",
    "\n",
    "print(centered_test_patches_by_category['Office'][list(centered_test_patches_by_category['Office'].keys())[0]][0].shape)\n",
    "print(centered_test_patches_by_category['Coast'][list(centered_test_patches_by_category['Coast'].keys())[0]][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "# Definir a categoria\n",
    "category = 'Coast'\n",
    "\n",
    "# Verificar se a categoria existe nos patches carregados\n",
    "if category in centered_test_patches_by_category:\n",
    "    # Obter os patches da categoria\n",
    "    category_patches = centered_test_patches_by_category[category]\n",
    "    \n",
    "    # Obter o primeiro image_id e seus patches correspondentes\n",
    "    if category_patches:\n",
    "        first_image_id = next(iter(category_patches))\n",
    "        patches, _ = category_patches[first_image_id]\n",
    "        \n",
    "        # Verificar se h√° patches\n",
    "        if patches.any():\n",
    "            # Definir o tamanho da grid\n",
    "            num_patches = len(patches)\n",
    "            grid_size = int(math.ceil(math.sqrt(num_patches)))\n",
    "            patch_size = int(len(patches[0]) ** 0.5)  # Assumindo que o patch √© quadrado\n",
    "            \n",
    "            # Criar uma figura com subplots para a grid\n",
    "            fig, axes = plt.subplots(grid_size, grid_size, figsize=(10, 10))\n",
    "            fig.suptitle(f'Patches da primeira imagem da categoria: {category}')\n",
    "            \n",
    "            # Preencher a grid com os patches\n",
    "            for i in range(grid_size):\n",
    "                for j in range(grid_size):\n",
    "                    patch_idx = i * grid_size + j\n",
    "                    if patch_idx < num_patches:\n",
    "                        patch = patches[patch_idx]\n",
    "                        axes[i, j].imshow(patch.reshape(patch_size, patch_size), cmap='gray')\n",
    "                    axes[i, j].axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Nenhum patch encontrado na primeira imagem.\")\n",
    "    else:\n",
    "        print(\"Nenhuma imagem encontrada nessa categoria.\")\n",
    "else:\n",
    "    print(f\"Categoria '{category}' n√£o encontrada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, images in test_patches_by_category.items():\n",
    "    count = 0\n",
    "    for image_id, (patches, positions) in images.items():\n",
    "        if count >= 3:\n",
    "            break\n",
    "        plot_distribution(patches, f'Original data distribution - {category} (Image ID: {image_id})')\n",
    "        centered_patches = centered_test_patches_by_category[category][image_id][0]\n",
    "        plot_distribution(centered_patches, f'Centered data distribution - {category} (Image ID: {image_id})')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should compute the projection into the residual space of a given data. The main logic here is to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ood(patches, residuals):\n",
    "    residual_norms = np.linalg.norm(residuals, axis=1)\n",
    "    original_norms = np.linalg.norm(patches, axis=1)\n",
    "    ood_scores = residual_norms / original_norms\n",
    "    return ood_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, pca in reduced_components_pca_by_category_90.items():\n",
    "    print(f\"Category: {category}, Number of components: {pca.n_components_}\")\n",
    "    print(f\"Explained variance by components: {pca.explained_variance_ratio_}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_residual_images_as_full_image(residuals_by_category, output_dir, patch_size=(32, 32), original_image_shape=(256, 256)):\n",
    "    for category, images in residuals_by_category.items():\n",
    "        category_dir = os.path.join(output_dir, category)\n",
    "        os.makedirs(category_dir, exist_ok=True)\n",
    "        \n",
    "        for image_id, (residuals, positions) in images.items():\n",
    "            residual_image = reassemble_image_from_patches(residuals, positions, original_image_shape, patch_size)\n",
    "            \n",
    "            residual_image = np.clip(residual_image, 0, 255)\n",
    "            residual_image = residual_image.astype(np.uint8)\n",
    "            \n",
    "            residual_image_filename = f\"residual_image_{image_id}.png\"\n",
    "            residual_image_path = os.path.join(category_dir, residual_image_filename)\n",
    "            cv2.imwrite(residual_image_path, residual_image)\n",
    "\n",
    "residuals_output_dir = \"different_reduced_components_pca_images_residuals\"\n",
    "\n",
    "def calculate_residuals_with_pca(pca_by_category, patches_by_category):\n",
    "    residuals_by_category = {}\n",
    "    for category, images in patches_by_category.items():\n",
    "        residuals_images = {}\n",
    "        for image_id, (patches, positions) in images.items():\n",
    "            pca = pca_by_category[category]\n",
    "            projected_data = pca.transform(patches)\n",
    "            reconstructed_data = pca.inverse_transform(projected_data)\n",
    "            residuals = patches - reconstructed_data\n",
    "            residuals_images[image_id] = (residuals, positions)\n",
    "        residuals_by_category[category] = residuals_images\n",
    "    return residuals_by_category\n",
    "\n",
    "all_components_residuals_by_category = calculate_residuals_with_pca(all_components_pca_by_category, centered_test_patches_by_category)\n",
    "\n",
    "reduced_components_residuals_by_category_95 = calculate_residuals_with_pca(reduced_components_pca_by_category_95, centered_test_patches_by_category)\n",
    "reduced_components_residuals_by_category_90 = calculate_residuals_with_pca(reduced_components_pca_by_category_90, centered_test_patches_by_category)\n",
    "reduced_components_residuals_by_category_85 = calculate_residuals_with_pca(reduced_components_pca_by_category_85, centered_test_patches_by_category)\n",
    "reduced_components_residuals_by_category_80 = calculate_residuals_with_pca(reduced_components_pca_by_category_80, centered_test_patches_by_category)\n",
    "\n",
    "save_residual_images_as_full_image(reduced_components_residuals_by_category_90, residuals_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ood_scores(residuals, original_patches):\n",
    "    if residuals.shape != original_patches.shape:\n",
    "        print(f\"Shape mismatch in calculate_ood_scores: residuals={residuals.shape}, original_patches={original_patches.shape}\")\n",
    "        return float('nan')\n",
    "    \n",
    "    scores = calculate_ood(original_patches, residuals)\n",
    "    ood_score = np.mean(scores)\n",
    "    return ood_score\n",
    "\n",
    "def process_and_calculate_ood(residuals_list, original_patches_list):\n",
    "    total_ood_scores = []\n",
    "    \n",
    "    # Iterate through residuals and original patches without concatenation\n",
    "    for (residuals, _), (original_patches, _) in zip(residuals_list, original_patches_list):\n",
    "        if residuals.shape[0] != original_patches.shape[0]:\n",
    "            print(f\"Mismatch in number of patches: residuals={residuals.shape[0]}, original_patches={original_patches.shape[0]}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate OOD score for each pair of residuals and original patches\n",
    "        ood_score = calculate_ood_scores(residuals, original_patches)\n",
    "        \n",
    "        if not np.isnan(ood_score):  # Ignore NaN scores\n",
    "            total_ood_scores.append(ood_score)\n",
    "    \n",
    "    if not total_ood_scores:\n",
    "        print(\"No data available for calculation.\")\n",
    "        return float('nan')\n",
    "    \n",
    "    # Return the mean OOD score across all images\n",
    "    return np.mean(total_ood_scores)\n",
    "\n",
    "\n",
    "coast_residuals = list(all_components_residuals_by_category['Coast'].values())\n",
    "office_residuals = list(all_components_residuals_by_category['Office'].values())\n",
    "\n",
    "coast_original_patches = list(centered_test_patches_by_category['Coast'].values())\n",
    "office_original_patches = list(centered_test_patches_by_category['Office'].values())\n",
    "\n",
    "ood_score_coast_train_coast_test = process_and_calculate_ood(coast_residuals, coast_original_patches)\n",
    "ood_score_coast_train_office_test = process_and_calculate_ood(coast_residuals, office_original_patches)\n",
    "ood_score_office_train_office_test = process_and_calculate_ood(office_residuals, office_original_patches)\n",
    "ood_score_office_train_coast_test = process_and_calculate_ood(office_residuals, coast_original_patches)\n",
    "\n",
    "print(\"OOD Scores using Coast test Data on Coast Testing Data:\")\n",
    "print(f\"OOD Score: {ood_score_coast_train_coast_test}\")\n",
    "\n",
    "print(\"\\nOOD Scores using Coast test Data on Office Testing Data:\")\n",
    "print(f\"OOD Score: {ood_score_coast_train_office_test}\")\n",
    "\n",
    "print(\"\\nOOD Scores using Office test Data on Office Testing Data:\")\n",
    "print(f\"OOD Score: {ood_score_office_train_office_test}\")\n",
    "\n",
    "print(\"\\nOOD Scores using Office test Data on Coast Testing Data:\")\n",
    "print(f\"OOD Score: {ood_score_office_train_coast_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_scores_all_levels = {\n",
    "    0.95: {\n",
    "        'coast_train_coast_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_95['Coast'].values()), list(centered_test_patches_by_category['Coast'].values())),\n",
    "        'coast_train_office_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_95['Coast'].values()), list(centered_test_patches_by_category['Office'].values())),\n",
    "        'office_train_office_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_95['Office'].values()), list(centered_test_patches_by_category['Office'].values())),\n",
    "        'office_train_coast_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_95['Office'].values()), list(centered_test_patches_by_category['Coast'].values()))\n",
    "    },\n",
    "    0.9: {\n",
    "        'coast_train_coast_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_90['Coast'].values()), list(centered_test_patches_by_category['Coast'].values())),\n",
    "        'coast_train_office_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_90['Coast'].values()), list(centered_test_patches_by_category['Office'].values())),\n",
    "        'office_train_office_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_90['Office'].values()), list(centered_test_patches_by_category['Office'].values())),\n",
    "        'office_train_coast_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_90['Office'].values()), list(centered_test_patches_by_category['Coast'].values()))\n",
    "    },\n",
    "    0.85: {\n",
    "        'coast_train_coast_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_85['Coast'].values()), list(centered_test_patches_by_category['Coast'].values())),\n",
    "        'coast_train_office_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_85['Coast'].values()), list(centered_test_patches_by_category['Office'].values())),\n",
    "        'office_train_office_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_85['Office'].values()), list(centered_test_patches_by_category['Office'].values())),\n",
    "        'office_train_coast_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_85['Office'].values()), list(centered_test_patches_by_category['Coast'].values()))\n",
    "    },\n",
    "    0.8: {\n",
    "        'coast_train_coast_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_80['Coast'].values()), list(centered_test_patches_by_category['Coast'].values())),\n",
    "        'coast_train_office_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_80['Coast'].values()), list(centered_test_patches_by_category['Office'].values())),\n",
    "        'office_train_office_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_80['Office'].values()), list(centered_test_patches_by_category['Office'].values())),\n",
    "        'office_train_coast_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_80['Office'].values()), list(centered_test_patches_by_category['Coast'].values()))\n",
    "    }\n",
    "}\n",
    "\n",
    "for variance, scores in ood_scores_all_levels.items():\n",
    "    print(f\"\\nVariance level: {variance}\")\n",
    "    for test_type, score in scores.items():\n",
    "        print(f\"{test_type}: OOD Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agnostic Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_results = {}\n",
    "\n",
    "# Lista de percentuais de vari√¢ncia explicada para os quais voc√™ quer calcular\n",
    "percentages = [95, 90, 85, 80]\n",
    "\n",
    "# Supondo que voc√™ tenha as vari√°veis 'reduced_components_pca_by_category_X' (onde X √© o percentual)\n",
    "# e que elas cont√™m os resultados do PCA\n",
    "for perc in percentages:\n",
    "    pca_data = globals().get(f'reduced_components_pca_by_category_{perc}', None)\n",
    "    \n",
    "    if pca_data is not None:\n",
    "        # Inicializar o dicion√°rio para o percentual espec√≠fico\n",
    "        pca_results[perc] = {}\n",
    "        \n",
    "        for category in categories:\n",
    "            if category in pca_data:\n",
    "                pca = pca_data[category]\n",
    "                components = pca.components_\n",
    "                explained_variance_ratio = pca.explained_variance_ratio_\n",
    "                \n",
    "                # Armazenar os componentes, a vari√¢ncia explicada e o pr√≥prio objeto PCA\n",
    "                pca_results[perc][category] = {\n",
    "                    'components': components,\n",
    "                    'explained_variance_ratio': explained_variance_ratio,\n",
    "                    'pca_object': pca  # Agora salvamos o PCA object tamb√©m\n",
    "                }\n",
    "            else:\n",
    "                print(f\"Categoria '{category}' n√£o est√° presente nos dados para {perc}%.\")\n",
    "    else:\n",
    "        print(f\"Dados de PCA n√£o encontrados para {perc}%.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_variance(explained_variance_ratio):\n",
    "    \"\"\"\n",
    "    Plota a vari√¢ncia explicada acumulada com base na vari√¢ncia explicada de cada componente principal.\n",
    "    \n",
    "    Parameters:\n",
    "    - explained_variance_ratio: Array ou lista contendo a vari√¢ncia explicada por componente.\n",
    "    \"\"\"\n",
    "    cumulative_variance = np.cumsum(explained_variance_ratio)  # Calcula a vari√¢ncia acumulada\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(np.arange(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='b')\n",
    "    plt.title('Cumulative Explained Variance')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se a estrutura de pca_results cont√©m a vari√¢ncia explicada\n",
    "percentage_to_use = 95  # Escolha a porcentagem que deseja usar\n",
    "category_to_use = 'Coast'  # Escolha a categoria para analisar\n",
    "\n",
    "if percentage_to_use in pca_results:\n",
    "    if category_to_use in pca_results[percentage_to_use]:\n",
    "        explained_variance_ratio = pca_results[percentage_to_use][category_to_use].get('explained_variance_ratio', None)\n",
    "        \n",
    "        if explained_variance_ratio is not None:\n",
    "            plot_cumulative_variance(explained_variance_ratio)\n",
    "        else:\n",
    "            print(f\"Explained variance ratio not found for {category_to_use} at {percentage_to_use}%.\")\n",
    "    else:\n",
    "        print(f\"Category '{category_to_use}' not found for {percentage_to_use}%.\")\n",
    "else:\n",
    "    print(f\"Percentage '{percentage_to_use}%' not found in pca_results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se a estrutura de pca_results cont√©m a vari√¢ncia explicada\n",
    "percentage_to_use = 95  # Escolha a porcentagem que deseja usar\n",
    "category_to_use = 'Office'  # Escolha a categoria para analisar\n",
    "\n",
    "if percentage_to_use in pca_results:\n",
    "    if category_to_use in pca_results[percentage_to_use]:\n",
    "        explained_variance_ratio = pca_results[percentage_to_use][category_to_use].get('explained_variance_ratio', None)\n",
    "        \n",
    "        if explained_variance_ratio is not None:\n",
    "            plot_cumulative_variance(explained_variance_ratio)\n",
    "        else:\n",
    "            print(f\"Explained variance ratio not found for {category_to_use} at {percentage_to_use}%.\")\n",
    "    else:\n",
    "        print(f\"Category '{category_to_use}' not found for {percentage_to_use}%.\")\n",
    "else:\n",
    "    print(f\"Percentage '{percentage_to_use}%' not found in pca_results.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Number of Components:\n",
    "\n",
    "The \"Coast\" category retained 23 components, while the \"Office\" category retained 22. This difference suggests that the amount of variance in the \"Coast\" data is more spread out across components compared to \"Office\".\n",
    "\n",
    "- Variance Explained:\n",
    "\n",
    "The first principal component in both categories captures the majority of the variance, but significantly more in \"Coast\" (80.18%) than in \"Office\" (70.35%). This indicates that the dominant pattern in \"Coast\" images is stronger or more distinct compared to \"Office\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fun√ß√£o para projetar patches nos componentes de uma categoria\n",
    "def project_test_patches(patches, pca_components):\n",
    "    return np.dot(patches, pca_components.T)\n",
    "\n",
    "# Fun√ß√£o para calcular normas, m√©dias e m√©dias das normas dos produtos internos no mesmo componente\n",
    "def calculate_norms_and_means(projections_A, projections_B):\n",
    "    norms = []\n",
    "    means = []\n",
    "    means_norms = []\n",
    "    \n",
    "    for i in range(projections_A.shape[1]):  # Itera sobre os componentes\n",
    "        dot_products = np.dot(projections_A[:, i], projections_B[:, i].T)\n",
    "        norms.append(np.linalg.norm(dot_products))\n",
    "        means.append(np.mean(dot_products))\n",
    "        means_norms.append(np.mean(np.linalg.norm(dot_products)))\n",
    "        \n",
    "    return norms, means, means_norms\n",
    "\n",
    "# Fun√ß√£o para plotar as normas m√©dias para todas as imagens combinadas\n",
    "def plot_mean_norms_for_all_images(category, other_category, mean_of_means_norms, color='blue'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotar os resultados para todos os componentes combinados em todas as imagens\n",
    "    plt.bar(range(len(mean_of_means_norms)), mean_of_means_norms, color=color,\n",
    "            label=f'{category} on {other_category} - All Images')\n",
    "    \n",
    "    plt.title(f'Mean of Norms for Components ({category} on {other_category}) - 95% Variance Explained')\n",
    "    plt.xlabel('Component Index')\n",
    "    plt.ylabel('Mean of Norms')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Lista de categorias para iterar\n",
    "categories = ['Coast', 'Office']\n",
    "\n",
    "# Trabalhando apenas com o PCA de 95% de vari√¢ncia explicada\n",
    "perc = 95\n",
    "\n",
    "# Iterar sobre as categorias para calcular tanto intra-categories quanto cross-categories\n",
    "for category in categories:\n",
    "    for other_category in categories:\n",
    "        # Carregar os componentes da pr√≥pria categoria ou da outra categoria\n",
    "        components = pca_results[perc][other_category]['components']\n",
    "        \n",
    "        if category == other_category:\n",
    "            print(f\"\\nCategory: {category} on {category} (Intra-Category), Percentage: {perc}%\")\n",
    "            color = 'blue'\n",
    "        else:\n",
    "            print(f\"\\nCategory: {category} on {other_category} (Cross-Category), Percentage: {perc}%\")\n",
    "            color = 'green'\n",
    "        \n",
    "        # Armazenar as normas m√©dias para todas as imagens\n",
    "        all_means_norms = []\n",
    "        \n",
    "        # Proje√ß√£o dos patches (intra ou cross-categoria) para todas as imagens\n",
    "        for image_id, (patches, positions) in centered_test_patches_by_category[category].items():\n",
    "            # Projeta os patches nos componentes\n",
    "            projected_patches = project_test_patches(patches, components)\n",
    "            \n",
    "            # Calcular normas, m√©dias e m√©dias das normas para cada imagem\n",
    "            _, _, means_norms_category = calculate_norms_and_means(projected_patches, projected_patches)\n",
    "            \n",
    "            # Armazenar as normas calculadas para a imagem\n",
    "            all_means_norms.append(means_norms_category)\n",
    "        \n",
    "        # Calcular a m√©dia das normas para todas as imagens\n",
    "        mean_of_means_norms = np.mean(all_means_norms, axis=0)  # M√©dia das normas em todas as imagens\n",
    "        \n",
    "        # Plotar os valores m√©dios das normas para todos os componentes combinados\n",
    "        plot_mean_norms_for_all_images(category, other_category, mean_of_means_norms, color=color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fun√ß√£o para projetar patches nos componentes de uma categoria\n",
    "def project_test_patches(patches, pca_components):\n",
    "    return np.dot(patches, pca_components.T)\n",
    "\n",
    "# Fun√ß√£o para calcular normas, m√©dias e m√©dias das normas dos produtos internos no mesmo componente\n",
    "def calculate_norms_and_means(projections_A, projections_B):\n",
    "    norms = []\n",
    "    means = []\n",
    "    means_norms = []\n",
    "    \n",
    "    for i in range(projections_A.shape[1]):  # Itera sobre os componentes\n",
    "        dot_products = np.dot(projections_A[:, i], projections_B[:, i].T)\n",
    "        norms.append(np.linalg.norm(dot_products))\n",
    "        means.append(np.mean(dot_products))\n",
    "        means_norms.append(np.mean(np.linalg.norm(dot_products)))\n",
    "        \n",
    "    return norms, means, means_norms\n",
    "\n",
    "# Fun√ß√£o para capturar componentes que explicam ~90% da vari√¢ncia com as menores normas, excluindo grandes normas\n",
    "def capture_components_by_variance_and_norm(explained_variance_ratio, norms, variance_threshold=0.9, norm_threshold=1e7):\n",
    "    # Calcular a vari√¢ncia explicada cumulativa\n",
    "    cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "    \n",
    "    # Capturar os √≠ndices que explicam at√© ~90% da vari√¢ncia\n",
    "    selected_indices = np.where(cumulative_variance <= variance_threshold)[0]\n",
    "    \n",
    "    # Excluir os componentes com normas muito grandes\n",
    "    selected_indices = [i for i in selected_indices if norms[i] < norm_threshold]\n",
    "    \n",
    "    # Ordenar os √≠ndices por norma\n",
    "    selected_indices = sorted(selected_indices, key=lambda idx: norms[idx])\n",
    "    \n",
    "    return selected_indices\n",
    "\n",
    "# Lista de categorias para iterar\n",
    "categories = ['Coast', 'Office']\n",
    "\n",
    "# Trabalhando apenas com o PCA de 95% de vari√¢ncia explicada\n",
    "perc = 95\n",
    "\n",
    "selected_indices_dict = {}\n",
    "\n",
    "# Iterar sobre as categorias para calcular tanto intra-categories quanto cross-categories\n",
    "for category in categories:\n",
    "    for other_category in categories:\n",
    "        # Carregar os componentes e vari√¢ncia explicada da pr√≥pria categoria ou da outra categoria\n",
    "        components = pca_results[perc][other_category]['components']\n",
    "        explained_variance_ratio = pca_results[perc][other_category]['explained_variance_ratio']\n",
    "        \n",
    "        if category == other_category:\n",
    "            print(f\"\\nCategory: {category} on {category} (Intra-Category), Percentage: {perc}%\")\n",
    "        else:\n",
    "            print(f\"\\nCategory: {category} on {other_category} (Cross-Category), Percentage: {perc}%\")\n",
    "        \n",
    "        # Proje√ß√£o dos patches (intra ou cross-categoria)\n",
    "        all_norms = []\n",
    "        all_selected_indices = []\n",
    "        \n",
    "        for image_id, (patches, positions) in centered_test_patches_by_category[category].items():\n",
    "            # Projeta os patches nos componentes\n",
    "            projected_patches = project_test_patches(patches, components)\n",
    "            \n",
    "            # Calcular normas, m√©dias e m√©dias das normas para cada imagem\n",
    "            norms_category, means_category, means_norms_category = calculate_norms_and_means(projected_patches, projected_patches)\n",
    "            \n",
    "            # Capturar os componentes que explicam at√© ~90% da vari√¢ncia com as menores normas, excluindo normas muito grandes\n",
    "            selected_indices = capture_components_by_variance_and_norm(explained_variance_ratio, norms_category)\n",
    "            \n",
    "            # Armazenar os resultados de normas e componentes selecionados\n",
    "            all_norms.append(norms_category)\n",
    "            all_selected_indices.append(selected_indices)\n",
    "        \n",
    "        # Verifique se existem componentes selecionados\n",
    "        if len(all_selected_indices) == 0 or np.concatenate(all_selected_indices).size == 0:\n",
    "            print(f\"Warning: No components selected for {category} on {other_category}. Skipping this combination.\")\n",
    "            continue\n",
    "\n",
    "        # Agregue os componentes selecionados em todas as imagens\n",
    "        aggregated_selected_indices = np.unique(np.concatenate(all_selected_indices))\n",
    "        \n",
    "        # Inicializar os dicion√°rios se as chaves n√£o existirem\n",
    "        if category not in selected_indices_dict:\n",
    "            selected_indices_dict[category] = {}\n",
    "        \n",
    "        selected_indices_dict[category][other_category] = aggregated_selected_indices\n",
    "\n",
    "        # Evite plotagens se n√£o houver componentes selecionados\n",
    "        if len(aggregated_selected_indices) == 0:\n",
    "            print(f\"Warning: No valid components selected for {category} on {other_category}. Skipping plot.\")\n",
    "            continue\n",
    "\n",
    "        # Plotar os resultados para os componentes selecionados\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(aggregated_selected_indices, [np.mean([norms[i] for norms in all_norms if i < len(norms)]) for i in aggregated_selected_indices], \n",
    "                color='green' if category != other_category else 'blue',\n",
    "                label=f'{category} on {other_category} - Selected Components')\n",
    "        plt.title(f'Selected Components Based on ~90% Variance and Smallest Norms ({category} on {other_category}) - 95% Variance Explained')\n",
    "        plt.xlabel('Component Index')\n",
    "        plt.ylabel('Mean of Norms')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_test_office_patches = centered_test_patches_by_category['Office']\n",
    "centered_test_coast_patches = centered_test_patches_by_category['Coast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Par√¢metros\n",
    "patch_size = (32, 32)\n",
    "\n",
    "def project_and_transform_back(data, pca, specific_indices):\n",
    "    \"\"\"\n",
    "    Projeta os dados nos componentes principais espec√≠ficos e reconstr√≥i a partir desses componentes.\n",
    "    \"\"\"\n",
    "    # Proje√ß√£o dos patches nos componentes principais\n",
    "    projected = pca.transform(data)\n",
    "    \n",
    "    # Usar apenas os componentes espec√≠ficos\n",
    "    projected_specific = projected[:, specific_indices]\n",
    "    \n",
    "    # Reconstruir os patches apenas com os componentes espec√≠ficos\n",
    "    specific_components = pca.components_[specific_indices]\n",
    "    reconstructed_patches = np.dot(projected_specific, specific_components)\n",
    "    \n",
    "    return reconstructed_patches\n",
    "\n",
    "def calculate_mean_ood_for_specific_components(original_patches_by_image, pca, specific_indices):\n",
    "    \"\"\"\n",
    "    Projeta os patches originais em componentes PCA espec√≠ficos, reconstr√≥i e calcula a m√©dia dos OOD scores.\n",
    "    \"\"\"\n",
    "    total_ood_scores = []\n",
    "    \n",
    "    # Itera sobre todas as imagens\n",
    "    for image_id, (patches, _) in original_patches_by_image.items():\n",
    "        # Proje√ß√£o e reconstru√ß√£o dos patches nos componentes espec√≠ficos\n",
    "        reconstructed_patches = project_and_transform_back(patches, pca, specific_indices)\n",
    "        \n",
    "        # Calcula os res√≠duos (erro de reconstru√ß√£o)\n",
    "        residuals = patches - reconstructed_patches\n",
    "        \n",
    "        # Calcular a pontua√ß√£o OOD (norma dos res√≠duos sobre a norma dos patches originais)\n",
    "        original_norms = np.linalg.norm(patches, axis=1)\n",
    "        residual_norms = np.linalg.norm(residuals, axis=1)\n",
    "        \n",
    "        # Calcular a pontua√ß√£o OOD para todos os patches\n",
    "        ood_scores = residual_norms / original_norms\n",
    "        \n",
    "        # Adiciona as pontua√ß√µes OOD desta imagem √† lista total\n",
    "        total_ood_scores.extend(ood_scores)\n",
    "    \n",
    "    # Retorna a m√©dia das pontua√ß√µes OOD\n",
    "    return np.mean(total_ood_scores)\n",
    "\n",
    "# Iterar sobre as categorias para calcular as m√©dias das pontua√ß√µes OOD\n",
    "mean_ood_scores = {}\n",
    "\n",
    "for category in categories:\n",
    "    for other_category in categories:\n",
    "        specific_indices = selected_indices_dict[category][other_category]\n",
    "        \n",
    "        # Recupera os objetos PCA para as categorias correspondentes\n",
    "        pca_object = pca_results[perc][other_category]['pca_object']  # Usamos os componentes do other_category\n",
    "        \n",
    "        # Verificar se os patches de teste existem para a categoria\n",
    "        if category not in centered_test_patches_by_category:\n",
    "            print(f\"Warning: No test patches found for {category}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        # Calcular a m√©dia das pontua√ß√µes OOD com base na proje√ß√£o nos componentes espec√≠ficos\n",
    "        mean_ood = calculate_mean_ood_for_specific_components(centered_test_patches_by_category[category], pca_object, specific_indices)\n",
    "        \n",
    "        # Armazenar a m√©dia no dicion√°rio\n",
    "        mean_ood_scores[f\"{category}_on_{other_category}\"] = mean_ood\n",
    "\n",
    "# Exibir todas as m√©dias calculadas\n",
    "for key, mean_ood in mean_ood_scores.items():\n",
    "    print(f\"Mean OOD Score for {key}: {mean_ood}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úåÔ∏è Part II: Comparing two similar environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categories = ['Bedroom', 'LivingRoom']\n",
    "\n",
    "df_similar = df[df['category'].isin(train_categories)]\n",
    "df_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_similar['image_path']\n",
    "y = df_similar['category']\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_images_set(X_train, X_test, y_train, y_test, patch_size, output_dir_train='patches_train', output_dir_test='patches_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_patches_by_category = load_patches_by_category('patches_train', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_training_patches_by_category = {}\n",
    "for category, images in training_patches_by_category.items():\n",
    "    centered_images = {}\n",
    "    for image_id, (patches, positions) in images.items():\n",
    "        centered_patches = center_patches(np.array(patches))\n",
    "        centered_images[image_id] = (centered_patches, positions)\n",
    "    centered_training_patches_by_category[category] = centered_images\n",
    "\n",
    "print(centered_training_patches_by_category['Bedroom'][list(centered_training_patches_by_category['Bedroom'].keys())[0]][0].shape)\n",
    "print(centered_training_patches_by_category['LivingRoom'][list(centered_training_patches_by_category['LivingRoom'].keys())[0]][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = train_categories\n",
    "base_input_dir = \"patches_train\"\n",
    "base_output_dir = \"similar_original_images_raw\"\n",
    "\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "training_patches_by_category = load_patches_by_category(base_input_dir, categories)\n",
    "\n",
    "for category, image_patches in training_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        centered_patches = center_patches(np.array(patches))\n",
    "        reconstructed_image = reassemble_image_from_patches(centered_patches, positions, original_image_shape, patch_size)\n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"reconstructed_image_{image_id}.png\")\n",
    "        save_reconstructed_image(reconstructed_image, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, images in training_patches_by_category.items():\n",
    "    count = 0\n",
    "    for image_id, (patches, positions) in images.items():\n",
    "        if count >= 3:\n",
    "            break\n",
    "        plot_distribution(patches, f'Original data distribution - {category} (Image ID: {image_id})')\n",
    "        centered_patches = centered_training_patches_by_category[category][image_id][0]\n",
    "        plot_distribution(centered_patches, f'Centered data distribution - {category} (Image ID: {image_id})')\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_components_pca_by_category = apply_all_components_pca(centered_training_patches_by_category)\n",
    "num_components_all_dict = {category: 1024 for category in centered_training_patches_by_category}\n",
    "visualize_pca_components(all_components_pca_by_category, num_components_all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_components_pca_by_category_95, num_components_reduced_dict_95, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.95)\n",
    "reduced_components_pca_by_category_90, num_components_reduced_dict_90, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.90)\n",
    "reduced_components_pca_by_category_85, num_components_reduced_dict_85, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.85)\n",
    "reduced_components_pca_by_category_80, num_components_reduced_dict_80, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_num_components(num_components_reduced_dict, variance_level):\n",
    "    print(f\"\\nNumber of Components for {variance_level*100}% Variance Explained:\")\n",
    "    for category, num_components in num_components_reduced_dict.items():\n",
    "        print(f\"Category: {category}, Number of Components: {num_components}\")\n",
    "\n",
    "# Imprimir o n√∫mero de componentes para cada n√≠vel de vari√¢ncia explicada\n",
    "print_num_components(num_components_reduced_dict_95, 0.95)\n",
    "print_num_components(num_components_reduced_dict_90, 0.90)\n",
    "print_num_components(num_components_reduced_dict_85, 0.85)\n",
    "print_num_components(num_components_reduced_dict_80, 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_components_pca_by_category = apply_all_components_pca(centered_training_patches_by_category)\n",
    "\n",
    "reconstructed_patches_by_category = project_and_reconstruct_patches(all_components_pca_by_category, centered_training_patches_by_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_dir = \"similar_all_components_pca_images_reconstructed\"\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "for category, image_patches in reconstructed_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        reconstructed_image = reassemble_image_from_patches(patches, positions, original_image_shape, patch_size)\n",
    "        \n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"reconstructed_image_{image_id}.png\")\n",
    "        save_reconstructed_image(reconstructed_image, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_reconstructed_patches_by_category = project_and_reconstruct_patches(reduced_components_pca_by_category_90, centered_training_patches_by_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_dir = \"similar_reduced_components_pca_images_reconstructed\"\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "for category, image_patches in reduced_reconstructed_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        reconstructed_image = reassemble_image_from_patches(patches, positions, original_image_shape, patch_size)\n",
    "        \n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"reconstructed_image_{image_id}.png\")\n",
    "        save_reconstructed_image(reconstructed_image, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patches_by_category = load_patches_by_category('patches_test', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_test_patches_by_category = {}\n",
    "\n",
    "for category, images in test_patches_by_category.items():\n",
    "    centered_images = {}\n",
    "    for image_id, (patches, positions) in images.items():\n",
    "        centered_patches = center_patches(np.array(patches))\n",
    "        centered_images[image_id] = (centered_patches, positions)\n",
    "    \n",
    "    centered_test_patches_by_category[category] = centered_images\n",
    "\n",
    "print(centered_test_patches_by_category['Bedroom'][list(centered_test_patches_by_category['Bedroom'].keys())[0]][0].shape)\n",
    "print(centered_test_patches_by_category['LivingRoom'][list(centered_test_patches_by_category['LivingRoom'].keys())[0]][0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, images in test_patches_by_category.items():\n",
    "    count = 0\n",
    "    for image_id, (patches, positions) in images.items():\n",
    "        if count >= 3:\n",
    "            break\n",
    "        plot_distribution(patches, f'Original data distribution - {category} (Image ID: {image_id})')\n",
    "        centered_patches = centered_test_patches_by_category[category][image_id][0]\n",
    "        plot_distribution(centered_patches, f'Centered data distribution - {category} (Image ID: {image_id})')\n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, pca in reduced_components_pca_by_category_90.items():\n",
    "    print(f\"Category: {category}, Number of components: {pca.n_components_}\")\n",
    "    print(f\"Explained variance by components: {pca.explained_variance_ratio_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residuals_output_dir = \"similar_reduced_components_pca_images_residuals\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_components_residuals_by_category = calculate_residuals_with_pca(all_components_pca_by_category, centered_test_patches_by_category)\n",
    "\n",
    "reduced_components_residuals_by_category_95 = calculate_residuals_with_pca(reduced_components_pca_by_category_95, centered_test_patches_by_category)\n",
    "reduced_components_residuals_by_category_90 = calculate_residuals_with_pca(reduced_components_pca_by_category_90, centered_test_patches_by_category)\n",
    "reduced_components_residuals_by_category_85 = calculate_residuals_with_pca(reduced_components_pca_by_category_85, centered_test_patches_by_category)\n",
    "reduced_components_residuals_by_category_80 = calculate_residuals_with_pca(reduced_components_pca_by_category_80, centered_test_patches_by_category)\n",
    "\n",
    "save_residual_images_as_full_image(reduced_components_residuals_by_category_90, residuals_output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bedroom_residuals = list(all_components_residuals_by_category['Bedroom'].values())\n",
    "LivingRoom_residuals = list(all_components_residuals_by_category['LivingRoom'].values())\n",
    "\n",
    "Bedroom_original_patches = list(centered_test_patches_by_category['Bedroom'].values())\n",
    "LivingRoom_original_patches = list(centered_test_patches_by_category['LivingRoom'].values())\n",
    "\n",
    "ood_score_Bedroom_train_Bedroom_test = process_and_calculate_ood(Bedroom_residuals, Bedroom_original_patches)\n",
    "ood_score_Bedroom_train_LivingRoom_test = process_and_calculate_ood(Bedroom_residuals, LivingRoom_original_patches)\n",
    "ood_score_LivingRoom_train_LivingRoom_test = process_and_calculate_ood(LivingRoom_residuals, LivingRoom_original_patches)\n",
    "ood_score_LivingRoom_train_Bedroom_test = process_and_calculate_ood(LivingRoom_residuals, Bedroom_original_patches)\n",
    "\n",
    "print(\"OOD Scores using Bedroom test Data on Bedroom Testing Data:\")\n",
    "print(f\"OOD Score: {ood_score_Bedroom_train_Bedroom_test}\")\n",
    "\n",
    "print(\"\\nOOD Scores using Bedroom test Data on LivingRoom Testing Data:\")\n",
    "print(f\"OOD Score: {ood_score_Bedroom_train_LivingRoom_test}\")\n",
    "\n",
    "print(\"\\nOOD Scores using LivingRoom test Data on LivingRoom Testing Data:\")\n",
    "print(f\"OOD Score: {ood_score_LivingRoom_train_LivingRoom_test}\")\n",
    "\n",
    "print(\"\\nOOD Scores using LivingRoom test Data on Bedroom Testing Data:\")\n",
    "print(f\"OOD Score: {ood_score_LivingRoom_train_Bedroom_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_scores_all_levels = {\n",
    "    0.95: {\n",
    "        'Bedroom_train_Bedroom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_95['Bedroom'].values()), list(centered_test_patches_by_category['Bedroom'].values())),\n",
    "        'Bedroom_train_LivingRoom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_95['Bedroom'].values()), list(centered_test_patches_by_category['LivingRoom'].values())),\n",
    "        'LivingRoom_train_LivingRoom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_95['LivingRoom'].values()), list(centered_test_patches_by_category['LivingRoom'].values())),\n",
    "        'LivingRoom_train_Bedroom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_95['LivingRoom'].values()), list(centered_test_patches_by_category['Bedroom'].values()))\n",
    "    },\n",
    "    0.9: {\n",
    "        'Bedroom_train_Bedroom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_90['Bedroom'].values()), list(centered_test_patches_by_category['Bedroom'].values())),\n",
    "        'Bedroom_train_LivingRoom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_90['Bedroom'].values()), list(centered_test_patches_by_category['LivingRoom'].values())),\n",
    "        'LivingRoom_train_LivingRoom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_90['LivingRoom'].values()), list(centered_test_patches_by_category['LivingRoom'].values())),\n",
    "        'LivingRoom_train_Bedroom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_90['LivingRoom'].values()), list(centered_test_patches_by_category['Bedroom'].values()))\n",
    "    },\n",
    "    0.85: {\n",
    "        'Bedroom_train_Bedroom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_85['Bedroom'].values()), list(centered_test_patches_by_category['Bedroom'].values())),\n",
    "        'Bedroom_train_LivingRoom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_85['Bedroom'].values()), list(centered_test_patches_by_category['LivingRoom'].values())),\n",
    "        'LivingRoom_train_LivingRoom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_85['LivingRoom'].values()), list(centered_test_patches_by_category['LivingRoom'].values())),\n",
    "        'LivingRoom_train_Bedroom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_85['LivingRoom'].values()), list(centered_test_patches_by_category['Bedroom'].values()))\n",
    "    },\n",
    "    0.8: {\n",
    "        'Bedroom_train_Bedroom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_80['Bedroom'].values()), list(centered_test_patches_by_category['Bedroom'].values())),\n",
    "        'Bedroom_train_LivingRoom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_80['Bedroom'].values()), list(centered_test_patches_by_category['LivingRoom'].values())),\n",
    "        'LivingRoom_train_LivingRoom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_80['LivingRoom'].values()), list(centered_test_patches_by_category['LivingRoom'].values())),\n",
    "        'LivingRoom_train_Bedroom_test': process_and_calculate_ood(list(reduced_components_residuals_by_category_80['LivingRoom'].values()), list(centered_test_patches_by_category['Bedroom'].values()))\n",
    "    }\n",
    "}\n",
    "\n",
    "for variance, scores in ood_scores_all_levels.items():\n",
    "    print(f\"\\nVariance level: {variance}\")\n",
    "    for test_type, score in scores.items():\n",
    "        print(f\"{test_type}: OOD Score: {score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agnostic Spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar o dicion√°rio para armazenar os resultados de PCA\n",
    "pca_results = {}\n",
    "\n",
    "# Lista de percentuais de vari√¢ncia explicada para os quais voc√™ quer calcular\n",
    "percentages = [95, 90, 85, 80]\n",
    "\n",
    "# Supondo que voc√™ tenha as vari√°veis 'reduced_components_pca_by_category_X' (onde X √© o percentual)\n",
    "# e que elas cont√™m os resultados do PCA\n",
    "for perc in percentages:\n",
    "    pca_data = globals().get(f'reduced_components_pca_by_category_{perc}', None)\n",
    "    \n",
    "    if pca_data is not None:\n",
    "        # Inicializar o dicion√°rio para o percentual espec√≠fico\n",
    "        pca_results[perc] = {}\n",
    "        \n",
    "        for category in categories:\n",
    "            if category in pca_data:\n",
    "                pca = pca_data[category]\n",
    "                components = pca.components_\n",
    "                explained_variance_ratio = pca.explained_variance_ratio_\n",
    "                \n",
    "                # Armazenar os componentes, a vari√¢ncia explicada e o pr√≥prio objeto PCA\n",
    "                pca_results[perc][category] = {\n",
    "                    'components': components,\n",
    "                    'explained_variance_ratio': explained_variance_ratio,\n",
    "                    'pca_object': pca  # Agora salvamos o PCA object tamb√©m\n",
    "                }\n",
    "            else:\n",
    "                print(f\"Categoria '{category}' n√£o est√° presente nos dados para {perc}%.\")\n",
    "    else:\n",
    "        print(f\"Dados de PCA n√£o encontrados para {perc}%.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_variance(explained_variance_ratio):\n",
    "    \"\"\"\n",
    "    Plota a vari√¢ncia explicada acumulada com base na vari√¢ncia explicada de cada componente principal.\n",
    "    \n",
    "    Parameters:\n",
    "    - explained_variance_ratio: Array ou lista contendo a vari√¢ncia explicada por componente.\n",
    "    \"\"\"\n",
    "    cumulative_variance = np.cumsum(explained_variance_ratio)  # Calcula a vari√¢ncia acumulada\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(np.arange(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='b')\n",
    "    plt.title('Cumulative Explained Variance')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se a estrutura de pca_results cont√©m a vari√¢ncia explicada\n",
    "percentage_to_use = 95  # Escolha a porcentagem que deseja usar\n",
    "category_to_use = 'LivingRoom'  # Escolha a categoria para analisar\n",
    "\n",
    "if percentage_to_use in pca_results:\n",
    "    if category_to_use in pca_results[percentage_to_use]:\n",
    "        explained_variance_ratio = pca_results[percentage_to_use][category_to_use].get('explained_variance_ratio', None)\n",
    "        \n",
    "        if explained_variance_ratio is not None:\n",
    "            plot_cumulative_variance(explained_variance_ratio)\n",
    "        else:\n",
    "            print(f\"Explained variance ratio not found for {category_to_use} at {percentage_to_use}%.\")\n",
    "    else:\n",
    "        print(f\"Category '{category_to_use}' not found for {percentage_to_use}%.\")\n",
    "else:\n",
    "    print(f\"Percentage '{percentage_to_use}%' not found in pca_results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar se a estrutura de pca_results cont√©m a vari√¢ncia explicada\n",
    "percentage_to_use = 95  # Escolha a porcentagem que deseja usar\n",
    "category_to_use = 'Bedroom'  # Escolha a categoria para analisar\n",
    "\n",
    "if percentage_to_use in pca_results:\n",
    "    if category_to_use in pca_results[percentage_to_use]:\n",
    "        explained_variance_ratio = pca_results[percentage_to_use][category_to_use].get('explained_variance_ratio', None)\n",
    "        \n",
    "        if explained_variance_ratio is not None:\n",
    "            plot_cumulative_variance(explained_variance_ratio)\n",
    "        else:\n",
    "            print(f\"Explained variance ratio not found for {category_to_use} at {percentage_to_use}%.\")\n",
    "    else:\n",
    "        print(f\"Category '{category_to_use}' not found for {percentage_to_use}%.\")\n",
    "else:\n",
    "    print(f\"Percentage '{percentage_to_use}%' not found in pca_results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fun√ß√£o para projetar patches nos componentes de uma categoria\n",
    "def project_test_patches(patches, pca_components):\n",
    "    return np.dot(patches, pca_components.T)\n",
    "\n",
    "# Fun√ß√£o para calcular normas, m√©dias e m√©dias das normas dos produtos internos no mesmo componente\n",
    "def calculate_norms_and_means(projections_A, projections_B):\n",
    "    norms = []\n",
    "    means = []\n",
    "    means_norms = []\n",
    "    \n",
    "    for i in range(projections_A.shape[1]):  # Itera sobre os componentes\n",
    "        dot_products = np.dot(projections_A[:, i], projections_B[:, i].T)\n",
    "        norms.append(np.linalg.norm(dot_products))\n",
    "        means.append(np.mean(dot_products))\n",
    "        means_norms.append(np.mean(np.linalg.norm(dot_products)))\n",
    "        \n",
    "    return norms, means, means_norms\n",
    "\n",
    "# Fun√ß√£o para plotar as normas m√©dias para todas as imagens combinadas\n",
    "def plot_mean_norms_for_all_images(category, other_category, mean_of_means_norms, color='blue'):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plotar os resultados para todos os componentes combinados em todas as imagens\n",
    "    plt.bar(range(len(mean_of_means_norms)), mean_of_means_norms, color=color,\n",
    "            label=f'{category} on {other_category} - All Images')\n",
    "    \n",
    "    plt.title(f'Mean of Norms for Components ({category} on {other_category}) - 95% Variance Explained')\n",
    "    plt.xlabel('Component Index')\n",
    "    plt.ylabel('Mean of Norms')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Lista de categorias para iterar\n",
    "categories = ['LivingRoom', 'Bedroom']\n",
    "\n",
    "# Trabalhando apenas com o PCA de 95% de vari√¢ncia explicada\n",
    "perc = 95\n",
    "\n",
    "# Iterar sobre as categorias para calcular tanto intra-categories quanto cross-categories\n",
    "for category in categories:\n",
    "    for other_category in categories:\n",
    "        # Carregar os componentes da pr√≥pria categoria ou da outra categoria\n",
    "        components = pca_results[perc][other_category]['components']\n",
    "        \n",
    "        if category == other_category:\n",
    "            print(f\"\\nCategory: {category} on {category} (Intra-Category), Percentage: {perc}%\")\n",
    "            color = 'blue'\n",
    "        else:\n",
    "            print(f\"\\nCategory: {category} on {other_category} (Cross-Category), Percentage: {perc}%\")\n",
    "            color = 'green'\n",
    "        \n",
    "        # Armazenar as normas m√©dias para todas as imagens\n",
    "        all_means_norms = []\n",
    "        \n",
    "        # Proje√ß√£o dos patches (intra ou cross-categoria) para todas as imagens\n",
    "        for image_id, (patches, positions) in centered_test_patches_by_category[category].items():\n",
    "            # Projeta os patches nos componentes\n",
    "            projected_patches = project_test_patches(patches, components)\n",
    "            \n",
    "            # Calcular normas, m√©dias e m√©dias das normas para cada imagem\n",
    "            _, _, means_norms_category = calculate_norms_and_means(projected_patches, projected_patches)\n",
    "            \n",
    "            # Armazenar as normas calculadas para a imagem\n",
    "            all_means_norms.append(means_norms_category)\n",
    "        \n",
    "        # Calcular a m√©dia das normas para todas as imagens\n",
    "        mean_of_means_norms = np.mean(all_means_norms, axis=0)  # M√©dia das normas em todas as imagens\n",
    "        \n",
    "        # Plotar os valores m√©dios das normas para todos os componentes combinados\n",
    "        plot_mean_norms_for_all_images(category, other_category, mean_of_means_norms, color=color)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fun√ß√£o para projetar patches nos componentes de uma categoria\n",
    "def project_test_patches(patches, pca_components):\n",
    "    return np.dot(patches, pca_components.T)\n",
    "\n",
    "# Fun√ß√£o para calcular normas, m√©dias e m√©dias das normas dos produtos internos no mesmo componente\n",
    "def calculate_norms_and_means(projections_A, projections_B):\n",
    "    norms = []\n",
    "    means = []\n",
    "    means_norms = []\n",
    "    \n",
    "    for i in range(projections_A.shape[1]):  # Itera sobre os componentes\n",
    "        dot_products = np.dot(projections_A[:, i], projections_B[:, i].T)\n",
    "        norms.append(np.linalg.norm(dot_products))\n",
    "        means.append(np.mean(dot_products))\n",
    "        means_norms.append(np.mean(np.linalg.norm(dot_products)))\n",
    "        \n",
    "    return norms, means, means_norms\n",
    "\n",
    "# Fun√ß√£o para capturar componentes que explicam ~90% da vari√¢ncia com as menores normas, excluindo grandes normas\n",
    "def capture_components_by_variance_and_norm(explained_variance_ratio, norms, variance_threshold=0.9, norm_threshold=1e7):\n",
    "    # Calcular a vari√¢ncia explicada cumulativa\n",
    "    cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "    \n",
    "    # Capturar os √≠ndices que explicam at√© ~90% da vari√¢ncia\n",
    "    selected_indices = np.where(cumulative_variance <= variance_threshold)[0]\n",
    "    \n",
    "    # Excluir os componentes com normas muito grandes\n",
    "    selected_indices = [i for i in selected_indices if norms[i] < norm_threshold]\n",
    "    \n",
    "    # Ordenar os √≠ndices por norma\n",
    "    selected_indices = sorted(selected_indices, key=lambda idx: norms[idx])\n",
    "    \n",
    "    return selected_indices\n",
    "\n",
    "# Lista de categorias para iterar\n",
    "categories = ['Bedroom', 'LivingRoom']\n",
    "\n",
    "# Trabalhando apenas com o PCA de 95% de vari√¢ncia explicada\n",
    "perc = 95\n",
    "\n",
    "selected_indices_dict = {}\n",
    "\n",
    "# Iterar sobre as categorias para calcular tanto intra-categories quanto cross-categories\n",
    "for category in categories:\n",
    "    for other_category in categories:\n",
    "        # Carregar os componentes e vari√¢ncia explicada da pr√≥pria categoria ou da outra categoria\n",
    "        components = pca_results[perc][other_category]['components']\n",
    "        explained_variance_ratio = pca_results[perc][other_category]['explained_variance_ratio']\n",
    "        \n",
    "        if category == other_category:\n",
    "            print(f\"\\nCategory: {category} on {category} (Intra-Category), Percentage: {perc}%\")\n",
    "        else:\n",
    "            print(f\"\\nCategory: {category} on {other_category} (Cross-Category), Percentage: {perc}%\")\n",
    "        \n",
    "        # Proje√ß√£o dos patches (intra ou cross-categoria)\n",
    "        all_norms = []\n",
    "        all_selected_indices = []\n",
    "        \n",
    "        for image_id, (patches, positions) in test_patches_by_category[category].items():\n",
    "            # Projeta os patches nos componentes\n",
    "            projected_patches = project_test_patches(patches, components)\n",
    "            \n",
    "            # Calcular normas, m√©dias e m√©dias das normas para cada imagem\n",
    "            norms_category, means_category, means_norms_category = calculate_norms_and_means(projected_patches, projected_patches)\n",
    "            \n",
    "            # Capturar os componentes que explicam at√© ~90% da vari√¢ncia com as menores normas, excluindo normas muito grandes\n",
    "            selected_indices = capture_components_by_variance_and_norm(explained_variance_ratio, norms_category)\n",
    "            \n",
    "            # Armazenar os resultados de normas e componentes selecionados\n",
    "            all_norms.append(norms_category)\n",
    "            all_selected_indices.append(selected_indices)\n",
    "        \n",
    "        # Verifique se existem componentes selecionados\n",
    "        if len(all_selected_indices) == 0 or np.concatenate(all_selected_indices).size == 0:\n",
    "            print(f\"Warning: No components selected for {category} on {other_category}. Skipping this combination.\")\n",
    "            continue\n",
    "\n",
    "        # Agregue os componentes selecionados em todas as imagens\n",
    "        aggregated_selected_indices = np.unique(np.concatenate(all_selected_indices))\n",
    "        \n",
    "        # Inicializar os dicion√°rios se as chaves n√£o existirem\n",
    "        if category not in selected_indices_dict:\n",
    "            selected_indices_dict[category] = {}\n",
    "        \n",
    "        selected_indices_dict[category][other_category] = aggregated_selected_indices\n",
    "\n",
    "        # Evite plotagens se n√£o houver componentes selecionados\n",
    "        if len(aggregated_selected_indices) == 0:\n",
    "            print(f\"Warning: No valid components selected for {category} on {other_category}. Skipping plot.\")\n",
    "            continue\n",
    "\n",
    "        # Plotar os resultados para os componentes selecionados\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(aggregated_selected_indices, [np.mean([norms[i] for norms in all_norms if i < len(norms)]) for i in aggregated_selected_indices], \n",
    "                color='green' if category != other_category else 'blue',\n",
    "                label=f'{category} on {other_category} - Selected Components')\n",
    "        plt.title(f'Selected Components Based on ~90% Variance and Smallest Norms ({category} on {other_category}) - 95% Variance Explained')\n",
    "        plt.xlabel('Component Index')\n",
    "        plt.ylabel('Mean of Norms')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_test_Bedroom_patches = centered_test_patches_by_category['Bedroom']\n",
    "centered_test_LivingRoom_patches = centered_test_patches_by_category['LivingRoom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Par√¢metros\n",
    "patch_size = (32, 32)\n",
    "\n",
    "def project_and_transform_back(data, pca, specific_indices):\n",
    "    \"\"\"\n",
    "    Projeta os dados nos componentes principais espec√≠ficos e reconstr√≥i a partir desses componentes.\n",
    "    \"\"\"\n",
    "    # Proje√ß√£o dos patches nos componentes principais\n",
    "    projected = pca.transform(data)\n",
    "    \n",
    "    # Usar apenas os componentes espec√≠ficos\n",
    "    projected_specific = projected[:, specific_indices]\n",
    "    \n",
    "    # Reconstruir os patches apenas com os componentes espec√≠ficos\n",
    "    specific_components = pca.components_[specific_indices]\n",
    "    reconstructed_patches = np.dot(projected_specific, specific_components)\n",
    "    \n",
    "    return reconstructed_patches\n",
    "\n",
    "def calculate_mean_ood_for_specific_components(original_patches_by_image, pca, specific_indices):\n",
    "    \"\"\"\n",
    "    Projeta os patches originais em componentes PCA espec√≠ficos, reconstr√≥i e calcula a m√©dia dos OOD scores.\n",
    "    \"\"\"\n",
    "    total_ood_scores = []\n",
    "    \n",
    "    # Itera sobre todas as imagens\n",
    "    for image_id, (patches, _) in original_patches_by_image.items():\n",
    "        # Proje√ß√£o e reconstru√ß√£o dos patches nos componentes espec√≠ficos\n",
    "        reconstructed_patches = project_and_transform_back(patches, pca, specific_indices)\n",
    "        \n",
    "        # Calcula os res√≠duos (erro de reconstru√ß√£o)\n",
    "        residuals = patches - reconstructed_patches\n",
    "        \n",
    "        # Calcular a pontua√ß√£o OOD (norma dos res√≠duos sobre a norma dos patches originais)\n",
    "        original_norms = np.linalg.norm(patches, axis=1)\n",
    "        residual_norms = np.linalg.norm(residuals, axis=1)\n",
    "        \n",
    "        # Calcular a pontua√ß√£o OOD para todos os patches\n",
    "        ood_scores = residual_norms / original_norms\n",
    "        \n",
    "        # Adiciona as pontua√ß√µes OOD desta imagem √† lista total\n",
    "        total_ood_scores.extend(ood_scores)\n",
    "    \n",
    "    # Retorna a m√©dia das pontua√ß√µes OOD\n",
    "    return np.mean(total_ood_scores)\n",
    "\n",
    "# Iterar sobre as categorias para calcular as m√©dias das pontua√ß√µes OOD\n",
    "mean_ood_scores = {}\n",
    "\n",
    "for category in categories:\n",
    "    for other_category in categories:\n",
    "        specific_indices = selected_indices_dict[category][other_category]\n",
    "        \n",
    "        # Recupera os objetos PCA para as categorias correspondentes\n",
    "        pca_object = pca_results[perc][other_category]['pca_object']  # Usamos os componentes do other_category\n",
    "        \n",
    "        # Verificar se os patches de teste existem para a categoria\n",
    "        if category not in centered_test_patches_by_category:\n",
    "            print(f\"Warning: No test patches found for {category}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Calcular a m√©dia das pontua√ß√µes OOD com base na proje√ß√£o nos componentes espec√≠ficos\n",
    "        mean_ood = calculate_mean_ood_for_specific_components(centered_test_patches_by_category[category], pca_object, specific_indices)\n",
    "        \n",
    "        # Armazenar a m√©dia no dicion√°rio\n",
    "        mean_ood_scores[f\"{category}_on_{other_category}\"] = mean_ood\n",
    "\n",
    "# Exibir todas as m√©dias calculadas\n",
    "for key, mean_ood in mean_ood_scores.items():\n",
    "    print(f\"Mean OOD Score for {key}: {mean_ood}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['image_path']\n",
    "y = df['category']\n",
    "(X_train, X_test, y_train, y_test) = train_test_split(X, y, test_size=0.2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_images_set(X_train, X_test, y_train, y_test, patch_size, output_dir_train='patches_train', output_dir_test='patches_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_patches_by_category(base_dir, categories):\n",
    "    patches_by_category = {}\n",
    "    \n",
    "    for category in categories:\n",
    "        category_patches = {}\n",
    "        category_dir = os.path.join(base_dir, str(category))\n",
    "        \n",
    "        for root, _, files in os.walk(category_dir):\n",
    "            files = [f for f in files if f.endswith('.png') and '_patch_' in f]\n",
    "            files = sorted(files, key=lambda x: (int(x.split('_')[1]), int(x.split('_')[3]), int(x.split('_')[4].split('.')[0])))\n",
    "\n",
    "            for filename in files:\n",
    "                try:\n",
    "                    parts = filename.split('_')\n",
    "                    image_id = int(parts[1])\n",
    "                    y = int(parts[3])\n",
    "                    x = int(parts[4].split('.')[0])\n",
    "                    patch = cv2.imread(os.path.join(root, filename), cv2.IMREAD_GRAYSCALE)\n",
    "                    if patch is not None:\n",
    "                        if image_id not in category_patches:\n",
    "                            category_patches[image_id] = ([], [])\n",
    "                        category_patches[image_id][0].append(patch.flatten())\n",
    "                        category_patches[image_id][1].append((y, x))\n",
    "                except (IndexError, ValueError) as e:\n",
    "                    print(f\"Error processing file {filename}: {e}\")\n",
    "                    continue\n",
    "\n",
    "        patches_by_category[category] = category_patches\n",
    "    \n",
    "    return patches_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_patches_by_category = load_patches_by_category('patches_train', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_patches(patches):\n",
    "    return patches - patches.mean(axis=0)\n",
    "\n",
    "centered_training_patches_by_category = {}\n",
    "for category, images in training_patches_by_category.items():\n",
    "    centered_images = {}\n",
    "    for image_id, (patches, positions) in images.items():\n",
    "        centered_patches = center_patches(np.array(patches))\n",
    "        centered_images[image_id] = (centered_patches, positions)\n",
    "    centered_training_patches_by_category[category] = centered_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category, images in centered_training_patches_by_category.items():\n",
    "    sorted_ids = sorted(images.keys())\n",
    "    print(f\"Sorted Image IDs for category {category}: {sorted_ids}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reassemble_image_from_patches(patches, positions, original_image_shape, patch_size):\n",
    "    reconstructed_image = np.zeros(original_image_shape, dtype=np.float32)\n",
    "    patch_height, patch_width = patch_size\n",
    "\n",
    "    for patch, (i, j) in zip(patches, positions):\n",
    "        if i + patch_height <= original_image_shape[0] and j + patch_width <= original_image_shape[1]:\n",
    "            patch = patch.reshape((patch_height, patch_width))\n",
    "            reconstructed_image[i:i + patch_height, j:j + patch_width] = patch\n",
    "\n",
    "    return reconstructed_image\n",
    "\n",
    "def save_reconstructed_image(reconstructed_image, save_path):\n",
    "    reconstructed_image_uint8 = np.clip(reconstructed_image, 0, 255).astype(np.uint8) #perdre d'info avec √ßa\n",
    "    cv2.imwrite(save_path, reconstructed_image_uint8)\n",
    "\n",
    "categories = df['category'].unique()\n",
    "base_input_dir = \"patches_train\"\n",
    "base_output_dir = \"all-env_original_images_raw\"\n",
    "\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "\n",
    "for category, image_patches in training_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        centered_patches = center_patches(np.array(patches))\n",
    "        reconstructed_image = reassemble_image_from_patches(centered_patches, positions, original_image_shape, patch_size)\n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"reconstructed_image_{image_id}.png\")\n",
    "        save_reconstructed_image(reconstructed_image, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_components_pca_by_category = apply_all_components_pca(centered_training_patches_by_category)\n",
    "num_components_all_dict = {category: 1024 for category in centered_training_patches_by_category}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_components_pca_by_category_95, num_components_reduced_dict_95, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.95)\n",
    "reduced_components_pca_by_category_90, num_components_reduced_dict_90, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.90)\n",
    "reduced_components_pca_by_category_85, num_components_reduced_dict_85, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.85)\n",
    "reduced_components_pca_by_category_80, num_components_reduced_dict_80, _ = apply_reduced_pca(centered_training_patches_by_category, number_variance=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_num_components(num_components_reduced_dict, variance_level):\n",
    "    print(f\"\\nNumber of Components for {variance_level*100}% Variance Explained:\")\n",
    "    for category, num_components in num_components_reduced_dict.items():\n",
    "        print(f\"Category: {category}, Number of Components: {num_components}\")\n",
    "\n",
    "# Imprimir o n√∫mero de componentes para cada n√≠vel de vari√¢ncia explicada\n",
    "print_num_components(num_components_reduced_dict_95, 0.95)\n",
    "print_num_components(num_components_reduced_dict_90, 0.90)\n",
    "print_num_components(num_components_reduced_dict_85, 0.85)\n",
    "print_num_components(num_components_reduced_dict_80, 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_and_reconstruct_patches(pca_by_category, centered_patches_by_category):\n",
    "    reconstructed_patches_by_category = {}\n",
    "\n",
    "    for category, pca in pca_by_category.items():\n",
    "        images = centered_patches_by_category[category]\n",
    "        reconstructed_images = {}\n",
    "        \n",
    "        for image_id, (centered_patches, positions) in images.items():\n",
    "            projected = pca.transform(centered_patches)\n",
    "            reconstructed_patches = pca.inverse_transform(projected)\n",
    "            reconstructed_images[image_id] = (reconstructed_patches, positions)\n",
    "        \n",
    "        reconstructed_patches_by_category[category] = reconstructed_images\n",
    "    \n",
    "    return reconstructed_patches_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_components_pca_by_category = apply_all_components_pca(centered_training_patches_by_category)\n",
    "\n",
    "reconstructed_patches_by_category = project_and_reconstruct_patches(all_components_pca_by_category, centered_training_patches_by_category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_dir = \"all-env_all_components_pca_images_reconstructed\"\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "for category, image_patches in reconstructed_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        reconstructed_image = reassemble_image_from_patches(patches, positions, original_image_shape, patch_size)\n",
    "        \n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "for category, image_patches in reconstructed_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        reconstructed_image = reassemble_image_from_patches(patches, positions, original_image_shape, patch_size)\n",
    "        \n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"reconstructed_image_{image_id}.png\")\n",
    "        save_reconstructed_image(reconstructed_image, output_path)\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"reconstructed_image_{image_id}.png\")\n",
    "        save_reconstructed_image(reconstructed_image, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_reconstructed_patches_by_category = project_and_reconstruct_patches(reduced_components_pca_by_category_90, centered_training_patches_by_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_output_dir = \"all-env_reduced_components_pca_images_reconstructed\"\n",
    "patch_size = (32, 32)\n",
    "original_image_shape = (256, 256)\n",
    "\n",
    "for category, image_patches in reduced_reconstructed_patches_by_category.items():\n",
    "    for image_id, (patches, positions) in image_patches.items():\n",
    "        reconstructed_image = reassemble_image_from_patches(patches, positions, original_image_shape, patch_size)\n",
    "        \n",
    "        output_dir = os.path.join(base_output_dir, category)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_path = os.path.join(output_dir, f\"reconstructed_image_{image_id}.png\")\n",
    "        save_reconstructed_image(reconstructed_image, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patches_by_category = load_patches_by_category('patches_test', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centered_test_patches_by_category = {}\n",
    "\n",
    "for category, images in test_patches_by_category.items():\n",
    "    centered_images = {}\n",
    "    for image_id, (patches, positions) in images.items():\n",
    "        centered_patches = center_patches(np.array(patches))\n",
    "        centered_images[image_id] = (centered_patches, positions)\n",
    "    \n",
    "    centered_test_patches_by_category[category] = centered_images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_residual_images_as_full_image(residuals_by_category, output_dir, patch_size=(32, 32), original_image_shape=(256, 256)):\n",
    "    for category, images in residuals_by_category.items():\n",
    "        category_dir = os.path.join(output_dir, category)\n",
    "        os.makedirs(category_dir, exist_ok=True)\n",
    "        \n",
    "        for image_id, (residuals, positions) in images.items():\n",
    "            residual_image = reassemble_image_from_patches(residuals, positions, original_image_shape, patch_size)\n",
    "            \n",
    "            residual_image = np.clip(residual_image, 0, 255)\n",
    "            residual_image = residual_image.astype(np.uint8)\n",
    "            \n",
    "            residual_image_filename = f\"residual_image_{image_id}.png\"\n",
    "            residual_image_path = os.path.join(category_dir, residual_image_filename)\n",
    "            cv2.imwrite(residual_image_path, residual_image)\n",
    "\n",
    "residuals_output_dir = \"all-env_reduced_components_pca_images_residuals\"\n",
    "\n",
    "def calculate_residuals_with_pca(pca_by_category, patches_by_category):\n",
    "    residuals_by_category = {}\n",
    "    for category, images in patches_by_category.items():\n",
    "        residuals_images = {}\n",
    "        for image_id, (patches, positions) in images.items():\n",
    "            pca = pca_by_category[category]\n",
    "            projected_data = pca.transform(patches)\n",
    "            reconstructed_data = pca.inverse_transform(projected_data)\n",
    "            residuals = patches - reconstructed_data\n",
    "            residuals_images[image_id] = (residuals, positions)\n",
    "        residuals_by_category[category] = residuals_images\n",
    "    return residuals_by_category\n",
    "\n",
    "all_components_residuals_by_category = calculate_residuals_with_pca(all_components_pca_by_category, centered_test_patches_by_category)\n",
    "\n",
    "reduced_components_residuals_by_category_95 = calculate_residuals_with_pca(reduced_components_pca_by_category_95, centered_test_patches_by_category)\n",
    "reduced_components_residuals_by_category_90 = calculate_residuals_with_pca(reduced_components_pca_by_category_90, centered_test_patches_by_category)\n",
    "reduced_components_residuals_by_category_85 = calculate_residuals_with_pca(reduced_components_pca_by_category_85, centered_test_patches_by_category)\n",
    "reduced_components_residuals_by_category_80 = calculate_residuals_with_pca(reduced_components_pca_by_category_80, centered_test_patches_by_category)\n",
    "\n",
    "save_residual_images_as_full_image(reduced_components_residuals_by_category_90, residuals_output_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "\n",
    "# Lista de categorias (ambientes)\n",
    "categories = ['Bedroom', 'Suburb', 'Industry', 'Kitchen', 'LivingRoom', 'Coast', 'Forest', \n",
    "              'Highway', 'InsideCity', 'Mountain', 'OpenCountry', 'Street', 'Building', \n",
    "              'Office', 'Store']\n",
    "\n",
    "# Fun√ß√£o para calcular os OOD scores por imagem\n",
    "def calculate_ood_scores(residuals, original_patches):\n",
    "    if residuals.shape != original_patches.shape:\n",
    "        print(f\"Shape mismatch in calculate_ood_scores: residuals={residuals.shape}, original_patches={original_patches.shape}\")\n",
    "        return float('nan')\n",
    "    \n",
    "    # Calcular o OOD score por imagem como a m√©dia da raz√£o entre norma do res√≠duo e norma do patch original\n",
    "    residual_norms = np.linalg.norm(residuals, axis=1)\n",
    "    original_norms = np.linalg.norm(original_patches, axis=1)\n",
    "    ood_scores = residual_norms / original_norms\n",
    "    return np.mean(ood_scores)\n",
    "\n",
    "# Fun√ß√£o para processar os dados e calcular OOD scores sem concatenar todos os patches\n",
    "def process_and_calculate_ood(residuals_by_image, original_patches_by_image):\n",
    "    total_ood_scores = []\n",
    "    \n",
    "    # Iterar sobre todas as imagens e calcular os OOD scores por imagem\n",
    "    for (residuals, _), (original_patches, _) in zip(residuals_by_image, original_patches_by_image):\n",
    "        if residuals.shape[0] != original_patches.shape[0]:\n",
    "            print(f\"Mismatch in number of patches: residuals={residuals.shape[0]}, original_patches={original_patches.shape[0]}\")\n",
    "            continue\n",
    "        \n",
    "        # Calcular o OOD score por imagem\n",
    "        ood_score = calculate_ood_scores(residuals, original_patches)\n",
    "        if not np.isnan(ood_score):\n",
    "            total_ood_scores.append(ood_score)\n",
    "    \n",
    "    if not total_ood_scores:\n",
    "        print(\"No valid data for calculation.\")\n",
    "        return float('nan')\n",
    "    \n",
    "    # Retorna a m√©dia dos OOD scores das imagens\n",
    "    return np.mean(total_ood_scores)\n",
    "\n",
    "# Iterar sobre todas as combina√ß√µes de pares de categorias (ambientes)\n",
    "ood_scores_dict = {}\n",
    "\n",
    "for category_train, category_test in itertools.product(categories, repeat=2):\n",
    "    try:\n",
    "        # Recuperar os res√≠duos dos testes e patches originais para as categorias de treino e teste\n",
    "        train_residuals = list(all_components_residuals_by_category[category_train].values())\n",
    "        test_original_patches = list(centered_test_patches_by_category[category_test].values())\n",
    "        \n",
    "        # Calcular o OOD score usando os res√≠duos e patches originais dos testes\n",
    "        ood_score = process_and_calculate_ood(train_residuals, test_original_patches)\n",
    "        \n",
    "        # Armazenar o resultado\n",
    "        ood_scores_dict[f\"{category_train}_train_on_{category_test}_test\"] = ood_score\n",
    "        print(f\"Mean OOD Score using {category_train} Test Data on {category_test} Test Data: {ood_score}\")\n",
    "    except KeyError as e:\n",
    "        print(f\"Data not available for {category_train} testing on {category_test} testing. Skipping.\")\n",
    "        continue\n",
    "\n",
    "# Exibir os resultados das pontua√ß√µes OOD para todas as combina√ß√µes\n",
    "for key, ood_score in ood_scores_dict.items():\n",
    "    print(f\"Mean OOD Score for {key}: {ood_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# Variance levels to evaluate\n",
    "variance_levels = [0.95, 0.9, 0.85, 0.8]\n",
    "\n",
    "# Lista de categorias (ambientes)\n",
    "categories = ['Bedroom', 'Suburb', 'Industry', 'Kitchen', 'LivingRoom', 'Coast', 'Forest', \n",
    "              'Highway', 'InsideCity', 'Mountain', 'OpenCountry', 'Street', 'Building', \n",
    "              'Office', 'Store']\n",
    "\n",
    "# Dicion√°rio para armazenar os scores OOD para cada n√≠vel de vari√¢ncia\n",
    "ood_scores_all_levels = {}\n",
    "\n",
    "# Iterar sobre cada n√≠vel de vari√¢ncia e calcular os OOD scores para todas as categorias\n",
    "for variance in variance_levels:\n",
    "    ood_scores_all_levels[variance] = {}\n",
    "    \n",
    "    # Iterar sobre todas as combina√ß√µes poss√≠veis de categorias de treino e teste\n",
    "    for category_train, category_test in itertools.product(categories, repeat=2):\n",
    "        try:\n",
    "            # Recuperar os res√≠duos e patches originais para as categorias de treino e teste\n",
    "            train_residuals = list(globals()[f\"reduced_components_residuals_by_category_{int(variance*100)}\"][category_train].values())\n",
    "            test_original_patches = list(centered_test_patches_by_category[category_test].values())\n",
    "            \n",
    "            # Calcular o OOD score\n",
    "            ood_score = process_and_calculate_ood(train_residuals, test_original_patches)\n",
    "            \n",
    "            # Armazenar o resultado\n",
    "            ood_scores_all_levels[variance][f\"{category_train}_train_{category_test}_test\"] = ood_score\n",
    "            print(f\"Variance {variance}: OOD Score using {category_train} Train Data on {category_test} Test Data: {ood_score}\")\n",
    "        \n",
    "        except KeyError as e:\n",
    "            print(f\"Data not available for {category_train} training on {category_test} testing at variance level {variance}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "# Exibir os resultados das pontua√ß√µes OOD para todas as combina√ß√µes e n√≠veis de vari√¢ncia\n",
    "for variance, scores in ood_scores_all_levels.items():\n",
    "    print(f\"\\n--- Variance level: {variance} ---\")\n",
    "    for test_type, score in scores.items():\n",
    "        print(f\"{test_type}: OOD Score: {score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exemplo do formato de `ood_scores_all_levels` preenchido com pontua√ß√µes OOD\n",
    "ood_scores_all_levels = {\n",
    "    0.95: {},\n",
    "    0.9: {},\n",
    "    0.85: {},\n",
    "    0.8: {}\n",
    "}\n",
    "\n",
    "# Inicializando categorias\n",
    "categories = ['Bedroom', 'Suburb', 'Industry', 'Kitchen', 'LivingRoom', 'Coast', 'Forest', \n",
    "              'Highway', 'InsideCity', 'Mountain', 'OpenCountry', 'Street', 'Building', \n",
    "              'Office', 'Store']\n",
    "\n",
    "# Preenchendo `ood_scores_all_levels` dinamicamente para todos os n√≠veis de vari√¢ncia\n",
    "for variance in ood_scores_all_levels.keys():\n",
    "    ood_scores_all_levels[variance] = {\n",
    "        f\"{category_train}_train_{category_test}_test\": process_and_calculate_ood(\n",
    "            list(globals()[f\"reduced_components_residuals_by_category_{int(variance*100)}\"][category_train].values()),\n",
    "            list(centered_test_patches_by_category[category_test].values())\n",
    "        )\n",
    "        for category_train in categories\n",
    "        for category_test in categories\n",
    "    }\n",
    "\n",
    "# Fun√ß√£o para gerar heatmap usando apenas matplotlib\n",
    "def plot_ood_heatmap(variance, ood_scores_all_levels):\n",
    "    # Obter todas as pontua√ß√µes OOD para o n√≠vel de vari√¢ncia espec√≠fico\n",
    "    ood_scores = ood_scores_all_levels[variance]\n",
    "    \n",
    "    # Construir a matriz de pontua√ß√µes OOD\n",
    "    score_matrix = np.zeros((len(categories), len(categories)))\n",
    "    \n",
    "    for i, category_train in enumerate(categories):\n",
    "        for j, category_test in enumerate(categories):\n",
    "            key = f\"{category_train}_train_{category_test}_test\"\n",
    "            score_matrix[i, j] = ood_scores[key]\n",
    "    \n",
    "    # Plotar o heatmap usando matplotlib\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(score_matrix, cmap=\"coolwarm\", interpolation='nearest')\n",
    "    \n",
    "    # Adicionar r√≥tulos aos eixos\n",
    "    plt.xticks(np.arange(len(categories)), categories, rotation=90)\n",
    "    plt.yticks(np.arange(len(categories)), categories)\n",
    "    \n",
    "    # Adicionar os valores no heatmap\n",
    "    for i in range(len(categories)):\n",
    "        for j in range(len(categories)):\n",
    "            plt.text(j, i, f\"{score_matrix[i, j]:.2f}\", ha=\"center\", va=\"center\", color=\"black\")\n",
    "    \n",
    "    # Adicionar t√≠tulos e r√≥tulos\n",
    "    plt.colorbar(label='OOD Score')\n",
    "    plt.title(f\"OOD Scores Heatmap for Variance Level {variance}\")\n",
    "    plt.xlabel(\"Test Category\")\n",
    "    plt.ylabel(\"Train Category\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Gerar heatmaps para cada n√≠vel de vari√¢ncia\n",
    "for variance in ood_scores_all_levels.keys():\n",
    "    plot_ood_heatmap(variance, ood_scores_all_levels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Inicializar o dicion√°rio para armazenar os resultados de PCA\n",
    "pca_results = {}\n",
    "\n",
    "# Lista de percentuais de vari√¢ncia explicada para os quais voc√™ quer calcular\n",
    "percentages = [95, 90, 85, 80]\n",
    "\n",
    "# Supondo que voc√™ tenha as vari√°veis 'reduced_components_pca_by_category_X' (onde X √© o percentual)\n",
    "# e que elas cont√™m os resultados do PCA\n",
    "for perc in percentages:\n",
    "    pca_data = globals().get(f'reduced_components_pca_by_category_{perc}', None)\n",
    "    \n",
    "    if pca_data is not None:\n",
    "        # Inicializar o dicion√°rio para o percentual espec√≠fico\n",
    "        pca_results[perc] = {}\n",
    "        \n",
    "        for category in categories:\n",
    "            if category in pca_data:\n",
    "                pca = pca_data[category]\n",
    "                components = pca.components_\n",
    "                explained_variance_ratio = pca.explained_variance_ratio_\n",
    "                \n",
    "                # Armazenar os componentes, a vari√¢ncia explicada e o pr√≥prio objeto PCA\n",
    "                pca_results[perc][category] = {\n",
    "                    'components': components,\n",
    "                    'explained_variance_ratio': explained_variance_ratio,\n",
    "                    'pca_object': pca  # Agora salvamos o PCA object tamb√©m\n",
    "                }\n",
    "            else:\n",
    "                print(f\"Categoria '{category}' n√£o est√° presente nos dados para {perc}%.\")\n",
    "    else:\n",
    "        print(f\"Dados de PCA n√£o encontrados para {perc}%.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cumulative_variance(explained_variance_ratio):\n",
    "    \"\"\"\n",
    "    Plota a vari√¢ncia explicada acumulada com base na vari√¢ncia explicada de cada componente principal.\n",
    "    \n",
    "    Parameters:\n",
    "    - explained_variance_ratio: Array ou lista contendo a vari√¢ncia explicada por componente.\n",
    "    \"\"\"\n",
    "    cumulative_variance = np.cumsum(explained_variance_ratio)  # Calcula a vari√¢ncia acumulada\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(np.arange(1, len(cumulative_variance) + 1), cumulative_variance, marker='o', linestyle='--', color='b')\n",
    "    plt.title('Cumulative Explained Variance')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Fun√ß√£o para projetar patches nos componentes de uma categoria\n",
    "def project_test_patches(patches, pca_components):\n",
    "    return np.dot(patches, pca_components.T)\n",
    "\n",
    "# Fun√ß√£o para calcular normas, m√©dias e m√©dias das normas dos produtos internos no mesmo componente\n",
    "def calculate_norms_and_means(projections_A, projections_B):\n",
    "    norms = []\n",
    "    means = []\n",
    "    means_norms = []\n",
    "    \n",
    "    for i in range(projections_A.shape[1]):  # Itera sobre os componentes\n",
    "        dot_products = np.dot(projections_A[:, i], projections_B[:, i].T)\n",
    "        norms.append(np.linalg.norm(dot_products))\n",
    "        means.append(np.mean(dot_products))\n",
    "        means_norms.append(np.mean(np.linalg.norm(dot_products)))\n",
    "        \n",
    "    return norms, means, means_norms\n",
    "\n",
    "# Fun√ß√£o para capturar componentes que explicam ~90% da vari√¢ncia com as menores normas, excluindo grandes normas\n",
    "def capture_components_by_variance_and_norm(explained_variance_ratio, norms, variance_threshold=0.9, norm_threshold=1e7):\n",
    "    # Calcular a vari√¢ncia explicada cumulativa\n",
    "    cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "    \n",
    "    # Capturar os √≠ndices que explicam at√© ~90% da vari√¢ncia\n",
    "    selected_indices = np.where(cumulative_variance <= variance_threshold)[0]\n",
    "    \n",
    "    # Excluir os componentes com normas muito grandes\n",
    "    selected_indices = [i for i in selected_indices if norms[i] < norm_threshold]\n",
    "    \n",
    "    # Ordenar os √≠ndices por norma\n",
    "    selected_indices = sorted(selected_indices, key=lambda idx: norms[idx])\n",
    "    \n",
    "    return selected_indices\n",
    "\n",
    "# Lista de categorias para iterar\n",
    "categories = ['Bedroom', 'Suburb', 'Industry', 'Kitchen', 'LivingRoom', 'Coast', 'Forest', \n",
    "              'Highway', 'InsideCity', 'Mountain', 'OpenCountry', 'Street', 'Building', \n",
    "              'Office', 'Store']\n",
    "\n",
    "# Trabalhando apenas com o PCA de 95% de vari√¢ncia explicada\n",
    "perc = 95\n",
    "\n",
    "selected_indices_dict = {}\n",
    "\n",
    "# Iterar sobre as categorias para calcular tanto intra-categories quanto cross-categories\n",
    "for category in categories:\n",
    "    for other_category in categories:\n",
    "        # Carregar os componentes e vari√¢ncia explicada da pr√≥pria categoria ou da outra categoria\n",
    "        components = pca_results[perc][other_category]['components']\n",
    "        explained_variance_ratio = pca_results[perc][other_category]['explained_variance_ratio']\n",
    "        \n",
    "        if category == other_category:\n",
    "            print(f\"\\nCategory: {category} on {category} (Intra-Category), Percentage: {perc}%\")\n",
    "        else:\n",
    "            print(f\"\\nCategory: {category} on {other_category} (Cross-Category), Percentage: {perc}%\")\n",
    "        \n",
    "        # Proje√ß√£o dos patches (intra ou cross-categoria)\n",
    "        all_norms = []\n",
    "        all_selected_indices = []\n",
    "        \n",
    "        for image_id, (patches, positions) in centered_test_patches_by_category[category].items():\n",
    "            # Projeta os patches nos componentes\n",
    "            projected_patches = project_test_patches(patches, components)\n",
    "            \n",
    "            # Calcular normas, m√©dias e m√©dias das normas para cada imagem\n",
    "            norms_category, means_category, means_norms_category = calculate_norms_and_means(projected_patches, projected_patches)\n",
    "            \n",
    "            # Capturar os componentes que explicam at√© ~90% da vari√¢ncia com as menores normas, excluindo normas muito grandes\n",
    "            selected_indices = capture_components_by_variance_and_norm(explained_variance_ratio, norms_category)\n",
    "            \n",
    "            # Armazenar os resultados de normas e componentes selecionados\n",
    "            all_norms.append(norms_category)\n",
    "            all_selected_indices.append(selected_indices)\n",
    "        \n",
    "        # Verifique se existem componentes selecionados\n",
    "        if len(all_selected_indices) == 0 or np.concatenate(all_selected_indices).size == 0:\n",
    "            print(f\"Warning: No components selected for {category} on {other_category}. Skipping this combination.\")\n",
    "            continue\n",
    "\n",
    "        # Agregue os componentes selecionados em todas as imagens\n",
    "        aggregated_selected_indices = np.unique(np.concatenate(all_selected_indices))\n",
    "        \n",
    "        # Inicializar os dicion√°rios se as chaves n√£o existirem\n",
    "        if category not in selected_indices_dict:\n",
    "            selected_indices_dict[category] = {}\n",
    "        \n",
    "        selected_indices_dict[category][other_category] = aggregated_selected_indices\n",
    "\n",
    "        # Evite plotagens se n√£o houver componentes selecionados\n",
    "        if len(aggregated_selected_indices) == 0:\n",
    "            print(f\"Warning: No valid components selected for {category} on {other_category}. Skipping plot.\")\n",
    "            continue\n",
    "\n",
    "        # Plotar os resultados para os componentes selecionados\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.bar(aggregated_selected_indices, [np.mean([norms[i] for norms in all_norms if i < len(norms)]) for i in aggregated_selected_indices], \n",
    "                color='green' if category != other_category else 'blue',\n",
    "                label=f'{category} on {other_category} - Selected Components')\n",
    "        plt.title(f'Selected Components Based on ~90% Variance and Smallest Norms ({category} on {other_category}) - 95% Variance Explained')\n",
    "        plt.xlabel('Component Index')\n",
    "        plt.ylabel('Mean of Norms')\n",
    "        plt.legend()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Par√¢metros\n",
    "patch_size = (32, 32)\n",
    "\n",
    "def project_and_transform_back(data, pca, specific_indices):\n",
    "    \"\"\"\n",
    "    Projeta os dados nos componentes principais espec√≠ficos e reconstr√≥i a partir desses componentes.\n",
    "    \"\"\"\n",
    "    # Proje√ß√£o dos patches nos componentes principais\n",
    "    projected = pca.transform(data)\n",
    "    \n",
    "    # Usar apenas os componentes espec√≠ficos\n",
    "    projected_specific = projected[:, specific_indices]\n",
    "    \n",
    "    # Reconstruir os patches apenas com os componentes espec√≠ficos\n",
    "    specific_components = pca.components_[specific_indices]\n",
    "    reconstructed_patches = np.dot(projected_specific, specific_components)\n",
    "    \n",
    "    return reconstructed_patches\n",
    "\n",
    "def calculate_mean_ood_for_specific_components(original_patches_by_image, pca, specific_indices):\n",
    "    \"\"\"\n",
    "    Projeta os patches originais em componentes PCA espec√≠ficos, reconstr√≥i e calcula a m√©dia dos OOD scores.\n",
    "    \"\"\"\n",
    "    total_ood_scores = []\n",
    "    \n",
    "    # Itera sobre todas as imagens\n",
    "    for image_id, (patches, _) in original_patches_by_image.items():\n",
    "        # Proje√ß√£o e reconstru√ß√£o dos patches nos componentes espec√≠ficos\n",
    "        reconstructed_patches = project_and_transform_back(patches, pca, specific_indices)\n",
    "        \n",
    "        # Calcula os res√≠duos (erro de reconstru√ß√£o)\n",
    "        residuals = patches - reconstructed_patches\n",
    "        \n",
    "        # Calcular a pontua√ß√£o OOD (norma dos res√≠duos sobre a norma dos patches originais)\n",
    "        original_norms = np.linalg.norm(patches, axis=1)\n",
    "        residual_norms = np.linalg.norm(residuals, axis=1)\n",
    "        \n",
    "        # Calcular a pontua√ß√£o OOD para todos os patches\n",
    "        ood_scores = residual_norms / original_norms\n",
    "        \n",
    "        # Adiciona as pontua√ß√µes OOD desta imagem √† lista total\n",
    "        total_ood_scores.extend(ood_scores)\n",
    "    \n",
    "    # Retorna a m√©dia das pontua√ß√µes OOD\n",
    "    return np.mean(total_ood_scores)\n",
    "\n",
    "# Iterar sobre as categorias para calcular as m√©dias das pontua√ß√µes OOD\n",
    "mean_ood_scores = {}\n",
    "\n",
    "for category in categories:\n",
    "    for other_category in categories:\n",
    "        # Verificar se os √≠ndices espec√≠ficos existem para esta combina√ß√£o de categoria\n",
    "        specific_indices = selected_indices_dict[category][other_category]\n",
    "        \n",
    "        # Recupera os objetos PCA para as categorias correspondentes\n",
    "        pca_object = pca_results[perc][other_category]['pca_object']  # Usamos os componentes do other_category\n",
    "        \n",
    "        # Verificar se os patches de teste existem para a categoria\n",
    "        if category not in centered_test_patches_by_category:\n",
    "            print(f\"Warning: No test patches found for {category}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Calcular a m√©dia das pontua√ß√µes OOD com base na proje√ß√£o nos componentes espec√≠ficos\n",
    "        mean_ood = calculate_mean_ood_for_specific_components(centered_test_patches_by_category[category], pca_object, specific_indices)\n",
    "        \n",
    "        # Armazenar a m√©dia no dicion√°rio\n",
    "        mean_ood_scores[f\"{category}_on_{other_category}\"] = mean_ood\n",
    "\n",
    "# Exibir todas as m√©dias calculadas\n",
    "for key, mean_ood in mean_ood_scores.items():\n",
    "    print(f\"Mean OOD Score for {key}: {mean_ood}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Lista de categorias dispon√≠veis\n",
    "categories = ['Bedroom', 'Suburb', 'Industry', 'Kitchen', 'LivingRoom', 'Coast', 'Forest', \n",
    "              'Highway', 'InsideCity', 'Mountain', 'OpenCountry', 'Street', 'Building', \n",
    "              'Office', 'Store']\n",
    "\n",
    "# Inicializar uma matriz vazia para armazenar os OOD scores\n",
    "ood_score_matrix = np.full((len(categories), len(categories)), np.nan)\n",
    "\n",
    "# Preencher a matriz com os OOD scores calculados\n",
    "for i, test_category in enumerate(categories):\n",
    "    for j, train_category in enumerate(categories):\n",
    "        key = f\"{test_category}_on_{train_category}\"\n",
    "        if key in mean_ood_scores:\n",
    "            ood_score_matrix[i, j] = mean_ood_scores[key]\n",
    "\n",
    "# Criar um DataFrame a partir da matriz de OOD scores para facilitar o plot\n",
    "ood_score_df = pd.DataFrame(ood_score_matrix, index=categories, columns=categories)\n",
    "\n",
    "# Plotar o heatmap usando apenas matplotlib\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "# Criar o heatmap com imshow\n",
    "cax = ax.imshow(ood_score_df, cmap=\"coolwarm\", aspect=\"auto\")\n",
    "\n",
    "# Adicionar os valores na matriz\n",
    "for i in range(len(categories)):\n",
    "    for j in range(len(categories)):\n",
    "        value = ood_score_matrix[i, j]\n",
    "        if not np.isnan(value):\n",
    "            ax.text(j, i, f'{value:.4f}', ha='center', va='center', color='black')\n",
    "\n",
    "# Configurar os eixos\n",
    "ax.set_xticks(np.arange(len(categories)))\n",
    "ax.set_yticks(np.arange(len(categories)))\n",
    "ax.set_xticklabels(categories, rotation=45, ha=\"right\")\n",
    "ax.set_yticklabels(categories)\n",
    "\n",
    "# Adicionar t√≠tulo e r√≥tulos dos eixos\n",
    "ax.set_title('Heatmap of OOD Scores for Test and Train Categories')\n",
    "ax.set_xlabel('Train Category')\n",
    "ax.set_ylabel('Test Category')\n",
    "\n",
    "# Adicionar a barra de cores (colorbar)\n",
    "fig.colorbar(cax, ax=ax, label='OOD Score')\n",
    "\n",
    "# Ajustar layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar o heatmap\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
